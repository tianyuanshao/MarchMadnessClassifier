{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianyuanshao/MarchMadnessClassifier/blob/main/CBProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxIthTMY-oXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06e178f-b855-4b86-d21f-c430668a4ae9"
      },
      "source": [
        "# Import drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4LsCLvRHThx"
      },
      "source": [
        "# Import libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import sklearn as sk\n",
        "import sklearn.metrics as skm\n",
        "from sklearn.decomposition import PCA             \n",
        "from sklearn.preprocessing import normalize       \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8FWYqx_Rl2t"
      },
      "source": [
        "# Import Libraries for Deep Learning\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer\n",
        "from pprint import pprint\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktDLufOIr2p7",
        "outputId": "abad0cdc-57b3-47e5-ce0b-c97a660df75b"
      },
      "source": [
        "# Bayes Optimization Library: https://github.com/fmfn/BayesianOptimization\n",
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aWvlqg5Rs8y"
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG_uhlAwJfeH"
      },
      "source": [
        "# Import datasets \n",
        "\n",
        "# ALL YEARS\n",
        "cbb = pd.read_csv('/content/drive/MyDrive/CS271P/FinalProject/Datafiles/cbb.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwV-BrAdxDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337a7e62-de68-4f78-803d-71df9bcbd42c"
      },
      "source": [
        "# EDA: Basics\n",
        "cbb.head(5)     # Obtain first 5 rows\n",
        "len(cbb['CONF'].unique())   # Obtain distinct number of CONF variables (Athletic conference of school participation)\n",
        "len(cbb.columns)    # Obtain total number of variables \n",
        "len(cbb.index)      # Obtain total number of rows\n",
        "cbb.dtypes          # Types per columns\n",
        "cbb.shape           # Dimensions of data frame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2455, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIZodYh5BPnz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "df87c941-78ed-44cb-9d06-5bb07960be22"
      },
      "source": [
        "# Check for duplicate rows\n",
        "cbb_duplicated = cbb[cbb.duplicated()]\n",
        "cbb_duplicated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEAM</th>\n",
              "      <th>CONF</th>\n",
              "      <th>G</th>\n",
              "      <th>W</th>\n",
              "      <th>ADJOE</th>\n",
              "      <th>ADJDE</th>\n",
              "      <th>BARTHAG</th>\n",
              "      <th>EFG_O</th>\n",
              "      <th>EFG_D</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TORD</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTRD</th>\n",
              "      <th>2P_O</th>\n",
              "      <th>2P_D</th>\n",
              "      <th>3P_O</th>\n",
              "      <th>3P_D</th>\n",
              "      <th>ADJ_T</th>\n",
              "      <th>WAB</th>\n",
              "      <th>POSTSEASON</th>\n",
              "      <th>SEED</th>\n",
              "      <th>YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [TEAM, CONF, G, W, ADJOE, ADJDE, BARTHAG, EFG_O, EFG_D, TOR, TORD, ORB, DRB, FTR, FTRD, 2P_O, 2P_D, 3P_O, 3P_D, ADJ_T, WAB, POSTSEASON, SEED, YEAR]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_US6Efosqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c1857f-16b5-4702-cb8e-3294fae61843"
      },
      "source": [
        "# EDA: Transforming Null Values/New Variable Assignments\n",
        "cbb.isnull().sum()    # Obtain number of null values for each variable\n",
        "\n",
        "# 1 = TRUE, 0 = FALSE\n",
        "cbb['MAKE'] = np.where(pd.isnull(cbb.SEED), 0, 1)   # Create new bool variable MAKE for team making it into tournament \n",
        "\n",
        "len(cbb.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KOiKts954wr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c3f1c33a-0259-40ba-db41-e6db120a8547"
      },
      "source": [
        "# EDA: Transforming Wins Over Games Variables to Win Percentages\n",
        "cbb.insert(2, 'WP', cbb.apply(lambda x:x['W']/x['G'], axis = 1))\n",
        "cbb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEAM</th>\n",
              "      <th>CONF</th>\n",
              "      <th>WP</th>\n",
              "      <th>G</th>\n",
              "      <th>W</th>\n",
              "      <th>ADJOE</th>\n",
              "      <th>ADJDE</th>\n",
              "      <th>BARTHAG</th>\n",
              "      <th>EFG_O</th>\n",
              "      <th>EFG_D</th>\n",
              "      <th>TOR</th>\n",
              "      <th>TORD</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTRD</th>\n",
              "      <th>2P_O</th>\n",
              "      <th>2P_D</th>\n",
              "      <th>3P_O</th>\n",
              "      <th>3P_D</th>\n",
              "      <th>ADJ_T</th>\n",
              "      <th>WAB</th>\n",
              "      <th>POSTSEASON</th>\n",
              "      <th>SEED</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MAKE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>North Carolina</td>\n",
              "      <td>ACC</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>40</td>\n",
              "      <td>33</td>\n",
              "      <td>123.3</td>\n",
              "      <td>94.9</td>\n",
              "      <td>0.9531</td>\n",
              "      <td>52.6</td>\n",
              "      <td>48.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>18.2</td>\n",
              "      <td>40.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>32.3</td>\n",
              "      <td>30.4</td>\n",
              "      <td>53.9</td>\n",
              "      <td>44.6</td>\n",
              "      <td>32.7</td>\n",
              "      <td>36.2</td>\n",
              "      <td>71.7</td>\n",
              "      <td>8.6</td>\n",
              "      <td>2ND</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>B10</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>40</td>\n",
              "      <td>36</td>\n",
              "      <td>129.1</td>\n",
              "      <td>93.6</td>\n",
              "      <td>0.9758</td>\n",
              "      <td>54.8</td>\n",
              "      <td>47.7</td>\n",
              "      <td>12.4</td>\n",
              "      <td>15.8</td>\n",
              "      <td>32.1</td>\n",
              "      <td>23.7</td>\n",
              "      <td>36.2</td>\n",
              "      <td>22.4</td>\n",
              "      <td>54.8</td>\n",
              "      <td>44.7</td>\n",
              "      <td>36.5</td>\n",
              "      <td>37.5</td>\n",
              "      <td>59.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>2ND</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Michigan</td>\n",
              "      <td>B10</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>40</td>\n",
              "      <td>33</td>\n",
              "      <td>114.4</td>\n",
              "      <td>90.4</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>53.9</td>\n",
              "      <td>47.7</td>\n",
              "      <td>14.0</td>\n",
              "      <td>19.5</td>\n",
              "      <td>25.5</td>\n",
              "      <td>24.9</td>\n",
              "      <td>30.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>54.7</td>\n",
              "      <td>46.8</td>\n",
              "      <td>35.2</td>\n",
              "      <td>33.2</td>\n",
              "      <td>65.9</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2ND</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Texas Tech</td>\n",
              "      <td>B12</td>\n",
              "      <td>0.815789</td>\n",
              "      <td>38</td>\n",
              "      <td>31</td>\n",
              "      <td>115.2</td>\n",
              "      <td>85.2</td>\n",
              "      <td>0.9696</td>\n",
              "      <td>53.5</td>\n",
              "      <td>43.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>22.8</td>\n",
              "      <td>27.4</td>\n",
              "      <td>28.7</td>\n",
              "      <td>32.9</td>\n",
              "      <td>36.6</td>\n",
              "      <td>52.8</td>\n",
              "      <td>41.9</td>\n",
              "      <td>36.5</td>\n",
              "      <td>29.7</td>\n",
              "      <td>67.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2ND</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gonzaga</td>\n",
              "      <td>WCC</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>39</td>\n",
              "      <td>37</td>\n",
              "      <td>117.8</td>\n",
              "      <td>86.3</td>\n",
              "      <td>0.9728</td>\n",
              "      <td>56.6</td>\n",
              "      <td>41.1</td>\n",
              "      <td>16.2</td>\n",
              "      <td>17.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>26.2</td>\n",
              "      <td>39.0</td>\n",
              "      <td>26.9</td>\n",
              "      <td>56.3</td>\n",
              "      <td>40.0</td>\n",
              "      <td>38.2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>71.5</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2ND</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2450</th>\n",
              "      <td>Michigan St.</td>\n",
              "      <td>B10</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>35</td>\n",
              "      <td>26</td>\n",
              "      <td>111.4</td>\n",
              "      <td>87.8</td>\n",
              "      <td>0.9392</td>\n",
              "      <td>50.6</td>\n",
              "      <td>44.5</td>\n",
              "      <td>20.8</td>\n",
              "      <td>19.2</td>\n",
              "      <td>36.1</td>\n",
              "      <td>27.6</td>\n",
              "      <td>36.6</td>\n",
              "      <td>32.4</td>\n",
              "      <td>50.4</td>\n",
              "      <td>44.3</td>\n",
              "      <td>34.1</td>\n",
              "      <td>30.1</td>\n",
              "      <td>64.4</td>\n",
              "      <td>6.7</td>\n",
              "      <td>S16</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2451</th>\n",
              "      <td>Arizona</td>\n",
              "      <td>P12</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>35</td>\n",
              "      <td>27</td>\n",
              "      <td>114.4</td>\n",
              "      <td>92.2</td>\n",
              "      <td>0.9229</td>\n",
              "      <td>52.5</td>\n",
              "      <td>46.6</td>\n",
              "      <td>19.5</td>\n",
              "      <td>19.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>26.7</td>\n",
              "      <td>37.4</td>\n",
              "      <td>32.9</td>\n",
              "      <td>50.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>37.1</td>\n",
              "      <td>35.8</td>\n",
              "      <td>66.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>S16</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2452</th>\n",
              "      <td>Oregon</td>\n",
              "      <td>P12</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>37</td>\n",
              "      <td>28</td>\n",
              "      <td>104.8</td>\n",
              "      <td>88.6</td>\n",
              "      <td>0.8728</td>\n",
              "      <td>49.3</td>\n",
              "      <td>46.4</td>\n",
              "      <td>21.4</td>\n",
              "      <td>22.0</td>\n",
              "      <td>35.8</td>\n",
              "      <td>27.2</td>\n",
              "      <td>38.4</td>\n",
              "      <td>33.3</td>\n",
              "      <td>49.1</td>\n",
              "      <td>44.9</td>\n",
              "      <td>33.3</td>\n",
              "      <td>33.4</td>\n",
              "      <td>69.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>S16</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2453</th>\n",
              "      <td>La Salle</td>\n",
              "      <td>A10</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>34</td>\n",
              "      <td>24</td>\n",
              "      <td>112.0</td>\n",
              "      <td>96.2</td>\n",
              "      <td>0.8516</td>\n",
              "      <td>51.9</td>\n",
              "      <td>49.3</td>\n",
              "      <td>17.1</td>\n",
              "      <td>21.3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.2</td>\n",
              "      <td>31.3</td>\n",
              "      <td>28.5</td>\n",
              "      <td>49.3</td>\n",
              "      <td>50.6</td>\n",
              "      <td>37.7</td>\n",
              "      <td>30.2</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>S16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2454</th>\n",
              "      <td>Florida Gulf Coast</td>\n",
              "      <td>ASun</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>35</td>\n",
              "      <td>24</td>\n",
              "      <td>103.4</td>\n",
              "      <td>96.3</td>\n",
              "      <td>0.6952</td>\n",
              "      <td>51.6</td>\n",
              "      <td>46.9</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.1</td>\n",
              "      <td>32.5</td>\n",
              "      <td>32.8</td>\n",
              "      <td>35.2</td>\n",
              "      <td>32.7</td>\n",
              "      <td>52.3</td>\n",
              "      <td>46.9</td>\n",
              "      <td>33.4</td>\n",
              "      <td>31.3</td>\n",
              "      <td>69.1</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>S16</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2455 rows Ã— 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    TEAM  CONF        WP   G   W  ADJOE  ADJDE  BARTHAG  \\\n",
              "0         North Carolina   ACC  0.825000  40  33  123.3   94.9   0.9531   \n",
              "1              Wisconsin   B10  0.900000  40  36  129.1   93.6   0.9758   \n",
              "2               Michigan   B10  0.825000  40  33  114.4   90.4   0.9375   \n",
              "3             Texas Tech   B12  0.815789  38  31  115.2   85.2   0.9696   \n",
              "4                Gonzaga   WCC  0.948718  39  37  117.8   86.3   0.9728   \n",
              "...                  ...   ...       ...  ..  ..    ...    ...      ...   \n",
              "2450        Michigan St.   B10  0.742857  35  26  111.4   87.8   0.9392   \n",
              "2451             Arizona   P12  0.771429  35  27  114.4   92.2   0.9229   \n",
              "2452              Oregon   P12  0.756757  37  28  104.8   88.6   0.8728   \n",
              "2453            La Salle   A10  0.705882  34  24  112.0   96.2   0.8516   \n",
              "2454  Florida Gulf Coast  ASun  0.685714  35  24  103.4   96.3   0.6952   \n",
              "\n",
              "      EFG_O  EFG_D   TOR  TORD   ORB   DRB   FTR  FTRD  2P_O  2P_D  3P_O  \\\n",
              "0      52.6   48.1  15.4  18.2  40.7  30.0  32.3  30.4  53.9  44.6  32.7   \n",
              "1      54.8   47.7  12.4  15.8  32.1  23.7  36.2  22.4  54.8  44.7  36.5   \n",
              "2      53.9   47.7  14.0  19.5  25.5  24.9  30.7  30.0  54.7  46.8  35.2   \n",
              "3      53.5   43.0  17.7  22.8  27.4  28.7  32.9  36.6  52.8  41.9  36.5   \n",
              "4      56.6   41.1  16.2  17.1  30.0  26.2  39.0  26.9  56.3  40.0  38.2   \n",
              "...     ...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "2450   50.6   44.5  20.8  19.2  36.1  27.6  36.6  32.4  50.4  44.3  34.1   \n",
              "2451   52.5   46.6  19.5  19.8  35.0  26.7  37.4  32.9  50.6  43.4  37.1   \n",
              "2452   49.3   46.4  21.4  22.0  35.8  27.2  38.4  33.3  49.1  44.9  33.3   \n",
              "2453   51.9   49.3  17.1  21.3  29.0  34.2  31.3  28.5  49.3  50.6  37.7   \n",
              "2454   51.6   46.9  21.0  22.1  32.5  32.8  35.2  32.7  52.3  46.9  33.4   \n",
              "\n",
              "      3P_D  ADJ_T   WAB POSTSEASON  SEED  YEAR  MAKE  \n",
              "0     36.2   71.7   8.6        2ND   1.0  2016     1  \n",
              "1     37.5   59.3  11.3        2ND   1.0  2015     1  \n",
              "2     33.2   65.9   6.9        2ND   3.0  2018     1  \n",
              "3     29.7   67.5   7.0        2ND   3.0  2019     1  \n",
              "4     29.0   71.5   7.7        2ND   1.0  2017     1  \n",
              "...    ...    ...   ...        ...   ...   ...   ...  \n",
              "2450  30.1   64.4   6.7        S16   3.0  2013     1  \n",
              "2451  35.8   66.8   4.6        S16   6.0  2013     1  \n",
              "2452  33.4   69.2   2.9        S16  12.0  2013     1  \n",
              "2453  30.2   66.0   0.3        S16  13.0  2013     1  \n",
              "2454  31.3   69.1  -4.0        S16  15.0  2013     1  \n",
              "\n",
              "[2455 rows x 26 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWfkdWYqvqaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e1872b1e-dcff-40f1-f384-734dca1a08b4"
      },
      "source": [
        "# EDA: Numerical Variables\n",
        "cbbnum = cbb.drop(columns = ['YEAR', 'CONF', 'POSTSEASON', 'SEED', 'MAKE'])  # Include only columns with numerical values\n",
        "cbbnum.describe()       # Summary statistics for numerical variables \n",
        "cbbnum.WP.hist()\n",
        "#cbbnum.G.hist()\n",
        "#cbbnum.W.hist()\n",
        "#cbbnum.ADJOE.hist()\n",
        "#cbbnum.ADJDE.hist()\n",
        "#cbbnum.BARTHAG.hist()\n",
        "#cbbnum.EFG_O.hist()\n",
        "#cbbnum.EFG_D.hist()\n",
        "#cbbnum.TOR.hist()\n",
        "#cbbnum.TORD.hist()\n",
        "#cbbnum.ORB.hist()\n",
        "#cbbnum.DRB.hist()\n",
        "#cbbnum.FTR.hist()\n",
        "#cbbnum.FTRD.hist()\n",
        "#cbbnum.2P_O.hist()\n",
        "#cbbnum.2P_D.hist()\n",
        "#cbbnum.3P_O.hist()\n",
        "#cbbnum.3P_D.hist()\n",
        "#cbbnum.ADJ_T.hist()\n",
        "#cbbnum.WAB.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb8eba22210>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MdyUaUMUDHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "1d386ed0-3780-4e63-c905-8b02108aebfb"
      },
      "source": [
        "# EDA: Heatmap\n",
        "cbbnew = cbb.drop(columns = ['SEED', 'POSTSEASON'])     # Drop columns with null values (already transformed)\n",
        "len(cbbnew.columns)\n",
        "cbbnew.isnull().sum()     # Check for null values\n",
        "\n",
        "# Can customize correlation method (Pearson by default): https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n",
        "sb.heatmap(cbbnew.corr())    # Plot heatmap for database"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb8eb8c8a90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjCD7LiymHGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3015f4e7-4b3f-42e5-8891-1d43beff4e82"
      },
      "source": [
        "# EDA: Mean Statistics for Teams\n",
        "byteam = cbbnew.groupby('TEAM')\n",
        "\n",
        "byteam.mean()\n",
        "\n",
        "byteam.MAKE.sum().sort_values(ascending = False)\n",
        "byteam.WP.mean().sort_values(ascending = False)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TEAM\n",
              "Gonzaga                   0.872512\n",
              "Villanova                 0.818782\n",
              "Virginia                  0.806197\n",
              "Wichita St.               0.795254\n",
              "Duke                      0.792960\n",
              "                            ...   \n",
              "Alabama A&M               0.243395\n",
              "Maine                     0.211023\n",
              "San Jose St.              0.206240\n",
              "Mississippi Valley St.    0.191263\n",
              "Chicago St.               0.174548\n",
              "Name: WP, Length: 355, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV1jYZhmNe4N"
      },
      "source": [
        "# EDA: Creating Training Data\n",
        "y = cbb['MAKE']         # Set target value to FINALS\n",
        "cbb['MAKE'].value_counts()\n",
        "cbb\n",
        "x = cbb.drop(columns = ['G', 'W', 'MAKE', 'POSTSEASON', 'SEED'], axis = 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4locx5ISaKv"
      },
      "source": [
        "# Find int types\n",
        "x.dtypes\n",
        "\n",
        "# Drop non-float types\n",
        "x.drop(columns = ['TEAM', 'CONF','YEAR', 'WAB'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1POJOng4-moa",
        "outputId": "b26b6556-cc57-4a94-8be0-8e14f7dd806a"
      },
      "source": [
        "#PCA for Dimensionality Reduction / Explained Variance of columns               \n",
        "A = x\n",
        "pca = PCA(n_components=17) \n",
        "B = pca.fit_transform(sk.preprocessing.scale(A))      # Scale data as each variable has different range\n",
        "plt.scatter(B[:,0], B[:,1])\n",
        "\n",
        "\n",
        "#print(pca.explained_variance_)\n",
        "#print(abs(pca.components_))\n",
        "#print(B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fb8eb90ac10>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "6SvbLMzyB2WL",
        "outputId": "2c586530-c9a0-4ee9-8833-d50ec6d9ef23"
      },
      "source": [
        "# Number of Principal Components    \n",
        "\n",
        "# https://towardsdatascience.com/dimensionality-reduction-can-pca-improve-the-performance-of-a-classification-model-d4e34194c544\n",
        "\n",
        "percent_var_explained = pca.explained_variance_/(np.sum(pca.explained_variance_))\n",
        "cumm_var_explained = np.cumsum(percent_var_explained)\n",
        "\n",
        "plt.plot(cumm_var_explained)\n",
        "plt.grid()\n",
        "plt.xlabel(\"n_components\")\n",
        "plt.ylabel(\"% variance explained\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM1wx18KCNHv",
        "outputId": "8db2bcac-9a85-40c7-8dcf-19ca6b80ddf6"
      },
      "source": [
        "# number of components to capture >50% is 2 and > 90% variance is 8\n",
        "\n",
        "# https://towardsdatascience.com/pca-is-not-feature-selection-3344fb764ae6  \n",
        "\n",
        "pca = PCA(n_components = 8)\n",
        "B = pca.fit_transform(sk.preprocessing.scale(A))\n",
        "\n",
        "# most important features for each PC\n",
        "\n",
        "num_pc = pca.components_.shape[0]\n",
        "most_important = [np.abs(pca.components_[i]).argmax() for i in range(num_pc)]\n",
        "                         \n",
        "feature_names = list(x.columns)\n",
        "important_names = [feature_names[most_important[i]] for i in range(num_pc)]\n",
        "\n",
        "dic_feature = {'PC{}'.format(i+1):important_names[i] for i in range(num_pc)}\n",
        "\n",
        "feature_pca = pd.DataFrame(dic_feature.items())\n",
        "\n",
        "print(feature_pca)\n",
        "print(x.var())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0        1\n",
            "0  PC1  BARTHAG\n",
            "1  PC2    EFG_D\n",
            "2  PC3     TORD\n",
            "3  PC4     TORD\n",
            "4  PC5    ADJ_T\n",
            "5  PC6      TOR\n",
            "6  PC7      DRB\n",
            "7  PC8      ORB\n",
            "WP          0.032301\n",
            "ADJOE      54.419841\n",
            "ADJDE      43.630227\n",
            "BARTHAG     0.065661\n",
            "EFG_O       9.878833\n",
            "EFG_D       8.641261\n",
            "TOR         4.370586\n",
            "TORD        4.847699\n",
            "ORB        17.092699\n",
            "DRB         9.931664\n",
            "FTR        27.539614\n",
            "FTRD       39.011270\n",
            "2P_O       11.454624\n",
            "2P_D       11.159247\n",
            "3P_O        7.780941\n",
            "3P_D        5.835928\n",
            "ADJ_T      10.742807\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI5ba9mWysS0"
      },
      "source": [
        "# Splitting into Test/Train Data (70% Train 20% Test 10% Validation)\n",
        "x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(x, y, test_size = 0.20,stratify = y, random_state = 7)\n",
        "B_train, B_test, B_y_train, B_y_test = sk.model_selection.train_test_split(B, y, test_size = 0.20, random_state = 7)\n",
        "# Splitting into Train/Validation Data\n",
        "x_train, x_val, y_train, y_val = sk.model_selection.train_test_split(x_train, y_train, test_size = 0.125, random_state = 7)\n",
        "B_train, B_val, B_y_train, B_y_val = sk.model_selection.train_test_split(B_train, B_y_train, test_size = 0.125, random_state = 7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrSVoqqWNzdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78c0801-5cd5-46f7-b16d-7c74f4a0d29d"
      },
      "source": [
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter = 10000, random_state= 7) \n",
        "cv = cross_val_score(lr, x, y, cv = 5)\n",
        "print(\"Accuracy: %0.2f%% (+/- %0.2f%%)\" % (cv.mean() * 100.0, cv.std() * 2))\n",
        "\n",
        "### Model with Split Train/Test Data\n",
        "lr.fit(x_train, y_train)\n",
        "lr_probs = lr.predict_proba(x_test)          ## for ROC Curves\n",
        "lr_probs = lr_probs[:,1]                     ## Keep probabilities for value with 1 only\n",
        "preds = lr.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "# K-Fold Cross Validation Approach \n",
        "cv = KFold(n_splits = 5, random_state = 1, shuffle = True)\n",
        "accuracy = cross_val_score(lr, x, y, scoring = 'accuracy', cv = cv, n_jobs = -1)\n",
        "print('Accuracy: %.3f%%  (+/- %.3f%%)' % (np.mean(accuracy) * 100.0, np.std(accuracy) ))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.22% (+/- 0.06%)\n",
            "Accuracy: 90.43%\n",
            "Accuracy: 90.672%  (+/- 0.009%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doqv9AJTObR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31790af2-dbef-4e83-a700-26485a820a4b"
      },
      "source": [
        "#### Model with Transformed B_Train/Test Data                       ## Same accuracy with PCA (89-92%)\n",
        "lr_B = LogisticRegression(max_iter = 10000, random_state=7)\n",
        "cv = cross_val_score(lr_B, B, y, cv = 5)\n",
        "print(\"Accuracy: %0.2f%% (+/- %0.2f%%)\" % (cv.mean() * 100.0, cv.std() * 2))\n",
        "\n",
        "### Model with Split Train/Test Data\n",
        "lr_B.fit(B_train, B_y_train)\n",
        "lr_probs_B = lr_B.predict_proba(B_test)          ## for ROC Curves\n",
        "lr_probs_B = lr_probs_B[:,1]                     ## Keep probabilities for value with 1 only\n",
        "preds_lr_B = lr_B.predict(B_test)\n",
        "accuracy= accuracy_score(B_y_test, preds_lr_B)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "# K-Fold Cross Validation Approach \n",
        "cv = KFold(n_splits = 5, random_state = 7, shuffle = True)\n",
        "accuracy = cross_val_score(lr_B, B, y, scoring = 'accuracy', cv = cv, n_jobs = -1)\n",
        "print('Accuracy: %.3f%%  (+/- %.3f%%)' % (np.mean(accuracy) * 100.0, np.std(accuracy) ))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 89.53% (+/- 0.06%)\n",
            "Accuracy: 91.85%\n",
            "Accuracy: 90.591%  (+/- 0.011%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrunmqo1B0v9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cc1178-0292-4b07-fb5b-464357fd4036"
      },
      "source": [
        "# Logistic Regression Parameter Tuning\n",
        "\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']     \n",
        "penalty = ['none','l1','l2','elasticnet']\n",
        "C_lr = [100, 10, 1, 0.1, 0.01]\n",
        "\n",
        "param_grid_lr = dict(C = C_lr, penalty = penalty, solver = solvers)\n",
        "\n",
        "grid_search_lr = GridSearchCV(lr, param_grid = param_grid_lr, n_jobs = -1, error_score = 0 )\n",
        "grid_search_lr.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(error_score=0,\n",
              "             estimator=LogisticRegression(max_iter=10000, random_state=7),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'C': [100, 10, 1, 0.1, 0.01],\n",
              "                         'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
              "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
              "                                    'saga']})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IBNc2UCGnUq",
        "outputId": "53abf131-4e12-47f2-bd5b-73d7c94c7576"
      },
      "source": [
        "#Parameter Tuning for PCA\n",
        "\n",
        "grid_search_lr_B = GridSearchCV(lr_B, param_grid = param_grid_lr, n_jobs = -1, error_score = 0 )\n",
        "grid_search_lr_B.fit(B_train,B_y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(error_score=0,\n",
              "             estimator=LogisticRegression(max_iter=10000, random_state=7),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'C': [100, 10, 1, 0.1, 0.01],\n",
              "                         'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
              "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
              "                                    'saga']})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLDvTOO9KNyj",
        "outputId": "a2539b65-3c97-4f5a-d0cf-f74842b8fe76"
      },
      "source": [
        "## Best Model from Hyper Parameters\n",
        "\n",
        "print(grid_search_lr.best_params_)\n",
        "print(grid_search_lr.best_estimator_)\n",
        "\n",
        "grid_pred_lr = grid_search_lr.predict(x_test)           \n",
        "accuracy_grid_lr = accuracy_score(y_test, grid_pred_lr)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_grid_lr * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "LogisticRegression(C=10, max_iter=10000, penalty='l1', random_state=7,\n",
            "                   solver='liblinear')\n",
            "Accuracy: 92.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CDiiw1fHENr",
        "outputId": "b80fbe6c-9a62-4c49-a6fa-09b37609af41"
      },
      "source": [
        "## Best Model from Hyper Parameters for B data\n",
        "\n",
        "print(grid_search_lr_B.best_params_)\n",
        "print(grid_search_lr_B.best_estimator_)\n",
        "\n",
        "grid_pred_lr_B = grid_search_lr_B.predict(B_test)           \n",
        "accuracy_grid_lr_B = accuracy_score(B_y_test, grid_pred_lr_B)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_grid_lr_B * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 100, 'penalty': 'none', 'solver': 'newton-cg'}\n",
            "LogisticRegression(C=100, max_iter=10000, penalty='none', random_state=7,\n",
            "                   solver='newton-cg')\n",
            "Accuracy: 91.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i361bjraUG1Y",
        "outputId": "10f5b70b-5cd8-4c8a-fbe2-0900dfa2c5f8"
      },
      "source": [
        "# Logistic Regression Model Evaluation\n",
        "# https://towardsdatascience.com/should-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1\n",
        "\n",
        "##### Confusion Matrix for Parameter Optimization\n",
        "cm = skm.confusion_matrix(y_test, grid_pred_lr)\n",
        "print('Confusion Matrix:', cm)\n",
        "\n",
        "##### Confusion Matrix for Transformed B Data   \n",
        "#cm = skm.confusion_matrix(B_y_test, preds_lr_B)\n",
        "#print('Confusion Matrix:', cm)\n",
        "\n",
        "\n",
        "##### Confusion Matrix          Baseline\n",
        "#cm = skm.confusion_matrix(y_test, preds)\n",
        "#print('Confusion Matrix:', cm)\n",
        "\n",
        "# Senstivity\n",
        "# TP/(TP + FN)\n",
        "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Sensitivity: ', sensitivity )\n",
        "\n",
        "# Specificity\n",
        "# TN/(TN + FP)\n",
        "specificity = cm[0,0]/(cm[0,0] + cm[0,1])\n",
        "print('Specificity: ', specificity)\n",
        "\n",
        "# Precision\n",
        "# TP/(TP + FP)\n",
        "precision = cm[1,1]/(cm[1,1] + cm[0,1])\n",
        "print('Precision: ', precision)\n",
        "\n",
        "# Recall\n",
        "# TP/(TP + FN)\n",
        "recall = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Recall: ', recall)\n",
        "\n",
        "# F1 Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[382  14]\n",
            " [ 25  70]]\n",
            "Sensitivity:  0.7368421052631579\n",
            "Specificity:  0.9646464646464646\n",
            "Precision:  0.8333333333333334\n",
            "Recall:  0.7368421052631579\n",
            "F1 Score:  0.782122905027933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em9HzOodKfrC"
      },
      "source": [
        "**CONFUSION MATRIX FOR BEST PARAMETERS**\n",
        "\n",
        "Confusion Matrix: [[382  14]\n",
        " [ 25  70]]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sensitivity:  0.7368421052631579\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Specificity:  0.9646464646464646\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Precision:  0.8333333333333334\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall:  0.7368421052631579\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "F1 Score:  0.782122905027933"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFGZ1V2YW3td"
      },
      "source": [
        "\n",
        "\n",
        "**PCA CONFUSION MATRIX**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eFQn1nlW1Sr"
      },
      "source": [
        "Confusion Matrix: \n",
        "[[374  19]\n",
        " [ 38  60]]\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sensitivity:  0.7363636363636363\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Specificity:  0.9711286089238845\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Precision:  0.8804347826086957\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Recall:  0.7363636363636363\n",
        "\n",
        "---\n",
        "\n",
        "F1 Score:  0.8019801980198019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Jg3P5IFnLz-2",
        "outputId": "9c4f50d0-f1a9-461a-a9e0-f45a48a3462a"
      },
      "source": [
        "# Logistic Regression ROC Curve \n",
        "lr_fpr, lr_tpr, _ = skm.roc_curve(y_test, lr_probs)\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label = 'Logistic')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZxdVX3v8c93kgnDwySkSSxIICEalEBiQkYITWugKAVBKIhA0CoUpQhovVhepIWLCFWxUEVs2gKCUMuDqNgbJZpbWxCuMJAMIJAA3jgwMAhlmE5gYgjJJL/+sffEk8k8nMmcfc6cs7/v12tesx/W2fu3Z5L57bXW3mspIjAzs/yqq3QAZmZWWU4EZmY550RgZpZzTgRmZjnnRGBmlnNjKx3AcE2ePDmmT59e6TDMzKpKS0vLaxExpb99VZcIpk+fzqpVqyodhplZVZHUNtA+Nw2ZmeWcE4GZWc45EZiZ5VzV9RH0Z/PmzbS3t7Nx48ZKhzJqNTQ0MHXqVOrr6ysdipmNMjWRCNrb22lsbGT69OlIqnQ4o05E0NnZSXt7O/vvv3+lwzGzUSazpiFJN0t6VdJTA+yXpOskrZX0hKRDdvZcGzduZNKkSU4CA5DEpEmTXGMys35l2UdwC3DMIPuPBWamX+cA/zSSkzkJDC7vP5+Wti6W3ruWlrauSoditlOy/DecWdNQRNwvafogRU4E/iWScbCbJe0pae+IeDmrmCyfWtq6OP2Gh9i8JagTvHuvRhob3Fdi1aN742aeeaWbCNilvo7bPrmA+dMmluz4lXxqaB/gxYL19nTbDiSdI2mVpFUdHR1lCW649thjjxEfY9WqVXz2s58dcP/zzz/P7bffXnT5Wjacu6Pm1k42b0nm3dga8MbGnqzDMyupNzb2sDUggM09W2lu7Szp8auiszgibgBuAGhqaqrZmXSamppoamoacH9vIjjjjDOKKl+rhnuH/19vbN83ct4R7+SMw/bLOkyzkmlp6+Kj32pmc89W6sfWsWDGpJIev5I1gpeAfQvWp6bbyqIcbcaPP/44CxYsYM6cOZx00kl0dSXnWrlyJXPmzGHu3LlcdNFFHHzwwQDcd999HH/88QD8/Oc/Z+7cucydO5d58+bR3d3NkiVLeOCBB5g7dy5f//rXtyu/fv16zjrrLGbPns2cOXP4wQ9+kNl1lcNgv5/h3uH3bP3dvUMd0LVhU0ljNcva/GkTue2TC7jw6HeVvFkIKlsjWAZcIOlO4DDg9VL0D3zxR6tZ85s3Bi3T2962NSjqjnLW28fzhQ8dNOxYPv7xj/PNb36TRYsWcdlll/HFL36Ra6+9lrPOOosbb7yRww8/nCVLlvT72WuuuYalS5eycOFC1q9fT0NDA1dddRXXXHMNP/7xj4EkcfS68sormTBhAk8++STAtqRTjYa64x/uHX7Wd1Nm5TB/2sSSJ4BeWT4+egfwEPAuSe2SzpZ0rqRz0yLLgVZgLXAjcF5WsfTV294G2bUZv/7666xbt45FixYB8IlPfIL777+fdevW0d3dzeGHHw6wrZmnr4ULF3LhhRdy3XXXsW7dOsaOHTxn/+xnP+P888/ftj5xYjb/YMrh7kfbB73jH+4dftZ3U2bVLsunhhYPsT+A8wcrszOKuXPve4f4jdPnjbo/DkuWLOG4445j+fLlLFy4kBUrVlQ6pLJoaevijkde2G5b3zv+nbnDz/Juyqza5XKsoXLcIU6YMIGJEyfywAMPAPCd73yHRYsWseeee9LY2MjDDz8MwJ133tnv53/9618ze/ZsLr74Yt773vfyzDPP0NjYSHd3d7/lP/CBD7B06dJt69XaNNTc2snWPo8D9L3j9x2+WWlVxVNDWSj1HeKGDRuYOnXqtvULL7yQW2+9lXPPPZcNGzYwY8YMvv3tbwNw00038alPfYq6ujoWLVrEhAkTdjjetddey7333ktdXR0HHXQQxx57LHV1dYwZM4b3vOc9nHnmmcybN29b+UsvvZTzzz+fgw8+mDFjxvCFL3yBk08+uWTXl5WWti6aWztZMGMS86dN3OHuftwAd/y+wzcrHSUtNNWjqakp+k5M8/TTT3PggQdWKKLhW79+/bb3Dq666ipefvllvvGNb2R+3tH2c+qvUxhgzctJrWeM4Mo/ne1HPc1KQFJLRPT7vHluawSVdM899/CVr3yFnp4epk2bxi233FLpkHZK37v54SrmMVA/6mmWPSeCCjjttNM47bTTKh3GiJRi2Ib+HgN9116NftTTrMxqJhFERO4HVhtMKZsAW9q6uPZnv9rhbn64iaC/x0B7O4JHUtMws+GpiUTQ0NBAZ2enh6IeQO98BA0NDSM+VmFNoNDODNsw0GOg7gg2K6+aSARTp06lvb2d0TogXSVs6tnKWz1b2GXsGMaNrds2Q9lIFbbr99rZYRt89282OtREIqivr/fMWwUGbr9/ZcTH7tuuL2Bc/c635fvu36zyaiIR2Pb6exqnVOPvF7brC/jDmZP53PsP8B9zsyrmRFCDFsyYRJ2SJNBQX9ohNPq26zsJmFU/J4IaNX7XsWzuCS45blZJ/1C7Xd+s9jgR1JiWti5Ovf5BtmxN1i//0WretVdjyZOBE4BZ7cjloHPVqpjJdJpbO7clAchmWjszqy2uEVSJYt/k7ftUz9gx8tu5ZjYoJ4JRrHAsn2KfBOr7VM9HmvZ1M46ZDcqJYJTqWwN4W+Mu2+0f6E3evk/1fPiQkb9EZma1zYkgQyMZnbNvDWDDpi3b9g32Jq+f6jGz4XIiyMhIR+fs29Z/xqH7cctDzxc1Kqef6jGz4XAiyEApRufsOzJn4671vtM3s0w4EZRYqUbn7G9kTt/pm1kWnAhKrFSjc7qt38zKxYmgxArH+QGo08ATsA/FNQAzKwcnggz0jvPzZwum0bhrve/ozWxU8xATJdQ7zs+6DT38dtMWbn7weScBMxv1nAhKyOP8mFk1ciIooYm7jdtufajn/c3MRgMnghJpaevif/+fJ7et1wku/9BBbhYys1HPiaBE7n60fbtmoYidm9DdzKzcnAhKoKWtizseeWG7bR7+2cyqhRNBCdz9aDtbt3+HzMM/m1nVyDQRSDpG0rOS1kpa0s/+/STdK+kxSU9I+mCW8WShv9pA/Rh5+GczqxqZJQJJY4ClwLHALGCxpFl9il0K3BUR84DTgX/MKp6sNLd2ujZgZlUtyxrBocDaiGiNiE3AncCJfcoEMD5dngD8JsN4MtH95ubt1sfUuTZgZtUly0SwD/BiwXp7uq3Q5cDHJLUDy4HP9HcgSedIWiVpVUdHRxax7rSH+rwwdvDbx7s2YGZVpdKdxYuBWyJiKvBB4DuSdogpIm6IiKaIaJoyZUrZgxxIS1sXT7S/vt22w/2kkJlVmSwTwUvAvgXrU9Nthc4G7gKIiIeABmByhjGVTO/kM326B2jctfjJZ8zMRoMsE8FKYKak/SWNI+kMXtanzAvAUQCSDiRJBKOr7acfvZPPPPD/X9tue73fHTCzKpRZIoiIHuACYAXwNMnTQaslXSHphLTY54FPSfolcAdwZkT0vckeVfpOQ9lL+GkhM6tOmc5HEBHLSTqBC7ddVrC8BliYZQylNNA0lAJ2qa/z00JmVpU8Mc0w3P1oe79J4A9nTuZz7z/AtQEzq0qVfmqoavT3BnFvTcBJwMyqmWsERervDWLXBMysFrhGUKQFMyahgvVxY10TMLPa4BpBkeZPm8iBezfSsf4tjp61FycfMtVJwMxqghPBMDQ21NPYUM+XTppd6VDMzErGTUNmZjnnRGBmlnNOBGZmOedEYGaWc0UnAkm7ZRmImZlVxpCJQNIfSFoDPJOuv0dS1U0pOVItbV20vrae515bT0tbV6XDMTMrmWJqBF8H/gToBIiIXwLvyzKo0aalrYtTr3+Qju5NvNq9icU3NjsZmFnNKKppKCJe7LNpSwaxjFp3P9rOlq2/W9/cs5XmPlNUmplVq2JeKHtR0h8AIake+EuS+QVyob/B5sZ6AhozqyHF1AjOBc4nmXj+JWAucF6WQY0WvZPQ9B1szhPQmFktKaZG8K6I+GjhBkkLgV9kE9LoMNAkNPVj5AlozKymFFMj+GaR22pKc2unp6M0s1wYsEYg6XDgD4Apki4s2DUeGJN1YJW2YMYk6sS2ZqE6JUNPuzZgZrVmsKahccAeaZnGgu1vAKdkGdRoMH/aRN69VyNvbOzhvCPeSdeGTSyYMcm1ATOrOQMmgoj4OfBzSbdERFsZYxo1eoedPuOw/SodiplZZorpLN4g6WrgIKChd2NE/HFmUY0CvW8SK112TcDMalUxncW3kQwvsT/wReB5YGWGMVWc3yQ2szwpJhFMioibgM0R8fOI+HOgpmsDfpPYzPKkmKahzen3lyUdB/wG+L3sQqosv0lsZnlTTCL4W0kTgM+TvD8wHvhcplFVUHNrp98kNrNcGTIRRMSP08XXgSNh25vFNWnBjEkI6M0FfnfAzGrdYC+UjQFOJRlj6KcR8ZSk44G/AXYF5pUnxPKbsNtYNm7ayvsOmMJfLHqHawNmVtMG6yy+CfgkMAm4TtK/AtcAfxcRNZkEep8WWrehh409W7nvVx2VDsnMLHODNQ01AXMiYqukBuAV4B0RUbOPzzS3dvb7tJBrBGZWywarEWyKiK0AEbERaB1uEpB0jKRnJa2VtGSAMqdKWiNptaTbh3P8UuvtH+hVP7bOTwuZWc0brEbwbklPpMsC3pGuC4iImDPYgdM+hqXAB4B2YKWkZRGxpqDMTOCvgYUR0SXpbSO4lhGbP20ivz9+Fzp/u4l5++7Jxcce6NqAmdW8wRLBgSM89qHA2ohoBZB0J3AisKagzKeApRHRBRARr47wnCNy+8Mv8MobbwHwyPNdPPtKtxOBmdW8AZuGIqJtsK8ijr0PUDjXcXu6rdABwAGSfiGpWdIx/R1I0jmSVkla1dGRXQfud1du/yLZT556ObNzmZmNFkVNXp+hscBM4AhgMXCjpD37FoqIGyKiKSKapkyZkkkgLW1dPNH++nbbDtp7fCbnMjMbTYp5s3hnvQTsW7A+Nd1WqB14OCI2A89J+hVJYijboHYtbV00t3bym3Vv0ueFYhp3rS9XGGZmFVNUIpC0K7BfRDw7jGOvBGZK2p8kAZwOnNGnzL+R1AS+LWkySVNR6zDOMSIDzUsMydzEfmLIzPJgyKYhSR8CHgd+mq7PlbRsqM9FRA9wAbACeBq4KyJWS7pC0glpsRVAp6Q1wL3AReV8T6G/eYnBcxObWb4UUyO4nOQJoPsAIuLx9C5/SBGxHFjeZ9tlBcsBXJh+lU1vc9DE3cZtG1do7BhRJ7Fly1bqPb6QmeVIUcNQR8TrUuGrVjs0p1eNwuagwsHl6oDLP3SQ5yY2s9wpJhGslnQGMCZ9AeyzwIPZhpWdwuagwmy2ZWvQtWET5x/5zsoEZmZWIcU8PvoZkvmK3wJuJxmOumrnI+h+c/N262PqxBh5OAkzy69iagTvjohLgEuyDqYcVr/8xnbrB799PEcftJebg8wst4qpEfy9pKclXSnp4MwjytixB++93fpp792P8498p5OAmeXWkIkgIo4kmZmsA7he0pOSLs08soyccdh+TJ+0G+MbxvLlk2ZzxmH7VTokM7OKKmqIiYh4JSKuA84leafgsiE+Mqr9/vgGDtx7vJOAmRnFvVB2oKTLJT1JMnn9gyTDRVSllrYuWl9bz3OvraelravS4ZiZVVwxNYKbgXXAn0TEERHxT5UeLnpn9U5F2dG9iVe7N7H4xmYnAzPLvSGfGoqIw8sRSDl4Kkozsx0NmAgk3RURp6ZNQoXvXhU1Q9lo1DsVZe/F+N0BM7PBawR/mX4/vhyBlMP8aRM5cO9GOta/xdGz9uLkQ6a6NmBmuTdgIoiI3um5zouIiwv3SfoqcPGOnxr9GhvqaWyo50snza50KGZmo0IxncUf6GfbsaUOxMzMKmOwPoJPA+cBMyQ9UbCrEfhF1oGZmVl5DNZHcDvwE+ArwJKC7d0R8d+ZRmVmZmUzWCKIiHhe0vl9d0j6PScDM7PaMFSN4HigheSJy8KZaQKYkWFcZmZWJoM9NXR8+r2oaSnNzKw6FTPW0EJJu6fLH5P0NUkerc3MrEYU8/joPwEbJL0H+Dzwa+A7mUZlZmZlU0wi6ImIAE4E/iEilpI8QmpmZjWgmKkquyX9NfBnwB9JqgPqsw3LzMzKpZgawWkkE9f/eUS8QjIXwdWZRmVmZmVTzFSVrwC3ARMkHQ9sjIh/yTwyMzMri2KeGjoVeAT4CHAq8LCkU7IOzMzMyqOYPoJLgPf2zkomaQrwM+D7WQZmZmblUUwfQV2fqSk7i/ycmZlVgWJqBD+VtAK4I10/DVieXUhmZlZOxcxZfJGkk4E/TDfdEBE/zDYsMzMrl8HmI5gJXAO8A3gS+KuIeKlcgWWhpa2L1tfWo3TZ01SamQ3e1n8z8GPgwyQjkH5zuAeXdIykZyWtlbRkkHIflhSSmoZ7jmK1tHVx6vUP0tG9iVe7N7H4xmZa2rqyOp2ZWdUYLBE0RsSNEfFsRFwDTB/OgSWNAZaSTGs5C1gsaVY/5RqBvwQeHs7xh6u5tZMtW3+3vrlnK82tnVme0sysKgzWR9AgaR6/m4dg18L1iHh0iGMfCqyNiFYASXeSjFe0pk+5K4GvAhcNM/ZhWTBjEiKZSAGgfmwdC2ZMyvKUZmZVYbBE8DLwtYL1VwrWA/jjIY69D/BiwXo7cFhhAUmHAPtGxD2SBkwEks4BzgHYb7+dGwF7/rSJHLh3Ix3r3+LoWXtx8iFT3UdgZsbgE9McmeWJ08HrvgacOVTZiLgBuAGgqakphig+oMaGehob6vnSSbN39hBmZjUnyxfDXgL2LVifmm7r1QgcDNwn6XlgAbAsyw5jMzPbUZaJYCUwU9L+ksYBpwPLendGxOsRMTkipkfEdKAZOCEiVmUYk5mZ9ZFZIoiIHuACYAXwNHBXRKyWdIWkE7I6r5mZDc+QbxZLEvBRYEZEXJHOV7xXRDwy1GcjYjl9hqOIiMsGKHtEURGbmVlJFVMj+EfgcGBxut5N8n6AmZnVgGIGnTssIg6R9BhARHSlbf5mZlYDiqkRbE7fEg7YNh/B1sE/YmZm1aKYRHAd8EPgbZK+BPw/4MuZRmVmZmVTzDDUt0lqAY4iGV7iTyPi6cwjMzOzsijmqaH9gA3Ajwq3RcQLWQZmZmblUUxn8T0k/QMCGoD9gWeBgzKMy8zMyqSYpqHtBuZJB4o7L7OIzMysrIb9ZnE6/PRhQxY0M7OqUEwfwYUFq3XAIcBvMovIzMzKqpg+gsaC5R6SPoMfZBOOmZmV26CJIH2RrDEi/qpM8ZiZWZkN2EcgaWxEbAEWljEeMzMrs8FqBI+Q9Ac8LmkZ8D3gt707I+LujGMzM7MyKKaPoAHoJJmjuPd9ggCcCMzMasBgieBt6RNDT/G7BNBrp+cNNjOz0WWwRDAG2IPtE0AvJwIzsxoxWCJ4OSKuKFskZmZWEYO9WdxfTcDMzGrMYIngqLJFUQYtbV20vrae515bT0tbV6XDMTMbNQZMBBHx3+UMJEstbV2cev2DdHRv4tXuTSy+sdnJwMwsNexB56pRc2snWwom19zcs5Xm1s7KBWRmNorkIhEsmDFpuw6P+rF1LJgxqWLxmJmNJsW8UFb15k+byIF7N9Kx/i2OnrUXJx8ylfnTJlY6LDOzUSEXiQCgsaGexoZ6vnTS7KELm5nlSC6ahszMbGBOBGZmOedEYGaWc04EZmY550RgZpZzmSYCScdIelbSWklL+tl/oaQ1kp6Q9B+SpmUZj5mZ7SizRJDOd7wUOBaYBSyWNKtPsceApoiYA3wf+Lus4jEzs/5lWSM4FFgbEa0RsQm4EzixsEBE3BsRG9LVZmBqhvGYmVk/skwE+wAvFqy3p9sGcjbwk/52SDpH0ipJqzo6OkoYopmZjYrOYkkfA5qAq/vbHxE3RERTRDRNmTKlvMGZmdW4LIeYeAnYt2B9arptO5LeD1wCLIqItzKMx8zM+pFljWAlMFPS/pLGAacDywoLSJoHXA+cEBGvZhiLmZkNILNEEBE9wAXACuBp4K6IWC3pCkknpMWuBvYAvifpcUnLBjicmZllJNPRRyNiObC8z7bLCpbfn+X5zcxsaKOis9jMzCrHicDMLOecCMzMcs6JwMws55wIzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyzonAzCzncpMIujdu5qV1b9LS1lXpUMzMRpVME4GkYyQ9K2mtpCX97N9F0nfT/Q9Lmp5FHC1tXTzzSjftXW/y0W81OxmYmRXILBFIGgMsBY4FZgGLJc3qU+xsoCsi3gl8HfhqFrE0t3ayNZLlTT1baW7tzOI0ZmZVKcsawaHA2ohojYhNwJ3AiX3KnAjcmi5/HzhKkkodyMTdxm1b3hrbr5uZ5V2WiWAf4MWC9fZ0W79lIqIHeB2Y1PdAks6RtErSqo6OjmEH0rVh07bluj7rZmZ5VxWdxRFxQ0Q0RUTTlClThv35BTMm0VBfxxjBuPo6FszYIdeYmeXW2AyP/RKwb8H61HRbf2XaJY0FJgAlb8CfP20it31yAc2tnSyYMYn50yaW+hRmZlUry0SwEpgpaX+SP/inA2f0KbMM+ATwEHAK8J8REVkEM3/aRCcAM7N+ZJYIIqJH0gXACmAMcHNErJZ0BbAqIpYBNwHfkbQW+G+SZGFmZmWUZY2AiFgOLO+z7bKC5Y3AR7KMwczMBlcVncVmZpYdJwIzs5xzIjAzyzknAjOznFNGT2tmRlIH0LaTH58MvFbCcKqBrzkffM35MJJrnhYR/b6RW3WJYCQkrYqIpkrHUU6+5nzwNedDVtfspiEzs5xzIjAzy7m8JYIbKh1ABfia88HXnA+ZXHOu+gjMzGxHeasRmJlZH04EZmY5V5OJQNIxkp6VtFbSkn727yLpu+n+hyVNL3+UpVXENV8oaY2kJyT9h6RplYizlIa65oJyH5YUkqr+UcNirlnSqenverWk28sdY6kV8W97P0n3Snos/ff9wUrEWSqSbpb0qqSnBtgvSdelP48nJB0y4pNGRE19kQx5/WtgBjAO+CUwq0+Z84B/TpdPB75b6bjLcM1HAruly5/OwzWn5RqB+4FmoKnScZfh9zwTeAyYmK6/rdJxl+GabwA+nS7PAp6vdNwjvOb3AYcATw2w/4PATwABC4CHR3rOWqwRHAqsjYjWiNgE3Amc2KfMicCt6fL3gaMkqYwxltqQ1xwR90bEhnS1mWTGuGpWzO8Z4Ergq8DGcgaXkWKu+VPA0ojoAoiIV8scY6kVc80BjE+XJwC/KWN8JRcR95PMzzKQE4F/iUQzsKekvUdyzlpMBPsALxast6fb+i0TET3A60A1T2RczDUXOpvkjqKaDXnNaZV534i4p5yBZaiY3/MBwAGSfiGpWdIxZYsuG8Vc8+XAxyS1k8x/8pnyhFYxw/3/PqRMJ6ax0UfSx4AmYFGlY8mSpDrga8CZFQ6l3MaSNA8dQVLru1/S7IhYV9GosrUYuCUi/l7S4SSzHh4cEVsrHVi1qMUawUvAvgXrU9Nt/ZaRNJakOtlZluiyUcw1I+n9wCXACRHxVpliy8pQ19wIHAzcJ+l5krbUZVXeYVzM77kdWBYRmyPiOeBXJImhWhVzzWcDdwFExENAA8ngbLWqqP/vw1GLiWAlMFPS/pLGkXQGL+tTZhnwiXT5FOA/I+2FqVJDXrOkecD1JEmg2tuNYYhrjojXI2JyREyPiOkk/SInRMSqyoRbEsX82/43ktoAkiaTNBW1ljPIEivmml8AjgKQdCBJIugoa5TltQz4ePr00ALg9Yh4eSQHrLmmoYjokXQBsILkiYObI2K1pCuAVRGxDLiJpPq4lqRT5vTKRTxyRV7z1cAewPfSfvEXIuKEigU9QkVec00p8ppXAEdLWgNsAS6KiKqt7RZ5zZ8HbpT0v0g6js+s5hs7SXeQJPPJab/HF4B6gIj4Z5J+kA8Ca4ENwFkjPmcV/7zMzKwEarFpyMzMhsGJwMws55wIzMxyzonAzCznnAjMzHLOicBGJUlbJD1e8DV9kLLrS3C+WyQ9l57r0fQN1eEe41uSZqXLf9Nn34MjjTE9Tu/P5SlJP5K05xDl51b7aJyWPT8+aqOSpPURsUepyw5yjFuAH0fE9yUdDVwTEXNGcLwRxzTUcSXdCvwqIr40SPkzSUZdvaDUsVjtcI3AqoKkPdJ5FB6V9KSkHUYalbS3pPsL7pj/KN1+tKSH0s9+T9JQf6DvB96ZfvbC9FhPSfpcum13SfdI+mW6/bR0+32SmiRdBeyaxnFbum99+v1OSccVxHyLpFMkjZF0taSV6Rjzf1HEj+Uh0sHGJB2aXuNjkh6U9K70TdwrgNPSWE5LY79Z0iNp2f5GbLW8qfTY2/7yV39fJG/FPp5+/ZDkLfjx6b7JJG9V9tZo16ffPw9cki6PIRlvaDLJH/bd0+0XA5f1c75bgFPS5Y8ADwPzgSeB3Uneyl4NzAM+DNxY8NkJ6ff7SOc86I2poExvjCcBt6bL40hGkdwVOAe4NN2+C7AK2L+fONcXXN/3gGPS9fHA2HT5/cAP0uUzgX8o+PyXgY+ly3uSjEW0e6V/3/6q7FfNDTFhNePNiJjbuyKpHviypPcBW0nuhH8feKXgMyuBm9Oy/xYRj0taRDJZyS/SoTXGkdxJ9+dqSZeSjFNzNsn4NT+MiN+mMdwN/BHwU+DvJX2VpDnpgWFc10+Ab0jaBTgGuD8i3kybo+ZIOiUtN4FksLjn+nx+V0mPp9f/NPDvBeVvlTSTZJiF+gHOfzRwgqS/StcbgP3SY1lOORFYtfgoMAWYHxGblYwo2lBYICLuTxPFccAtkr4GdAH/HhGLizjHRRHx/d4VSUf1VygifqVkroMPAn8r6T8i4opiLiIiNkq6D/gT4E+0FgQAAAFqSURBVDSSiVYgmW3qMxGxYohDvBkRcyXtRjL+zvnAdSQT8NwbESelHev3DfB5AR+OiGeLidfywX0EVi0mAK+mSeBIYIc5l5XMw/xfEXEj8C2S6f6agYWSetv8d5d0QJHnfAD4U0m7SdqdpFnnAUlvBzZExL+SDObX35yxm9OaSX++SzJQWG/tApI/6p/u/YykA9Jz9iuS2eY+C3xevxtKvXco4jMLinaTNJH1WgF8Rmn1SMmotJZzTgRWLW4DmiQ9CXwceKafMkcAv5T0GMnd9jciooPkD+Mdkp4gaRZ6dzEnjIhHSfoOHiHpM/hWRDwGzAYeSZtovgD8bT8fvwF4orezuI//SzIx0M8imX4RksS1BnhUyaTl1zNEjT2N5QmSiVn+DvhKeu2Fn7sXmNXbWUxSc6hPY1udrlvO+fFRM7Occ43AzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyzonAzCzn/gdG/JWTYqDu8wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2cj6k6WtFAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c51838c-ec0d-4119-8f45-d21624746640"
      },
      "source": [
        "# Hyperparameter tweaking for XGBoost using Bayesian Optimization\n",
        "##### https://aiinpractice.com/xgboost-hyperparameter-tuning-with-bayesian-optimization/\n",
        "##### https://github.com/fmfn/BayesianOptimization/blob/master/examples/sklearn_example.py\n",
        "\n",
        "# Define function that returns the mean of cross validation scores per hyperparameters passed in\n",
        "def xgboost_crossval(n_estimators, max_depth, learning_rate, gamma):\n",
        "\n",
        "  # Cast max_depth and n_estimators to integers\n",
        "  max_depth = int(max_depth)\n",
        "  n_estimators = int(n_estimators)\n",
        "\n",
        "  # Train model and calculate cross validation score\n",
        "  xg_class = xgb.XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, gamma=gamma, seed = 7)\n",
        "  accuracy = cross_val_score(xg_class, x_train, y_train, scoring='accuracy', cv=5) \n",
        "  \n",
        "  # Return mean of cross_val_scores\n",
        "  return np.mean(accuracy)\n",
        "\n",
        "\n",
        "# Call BayesionOptimization to check scores for various hyperparameters\n",
        "optimizer = BayesianOptimization(\n",
        "            f=xgboost_crossval,\n",
        "            pbounds={'n_estimators': (5, 100),\n",
        "                       'max_depth': (2,10),\n",
        "                       'learning_rate': (0.01, 1.0),\n",
        "                       'gamma': (1, 5)},\n",
        "            random_state=7)\n",
        "\n",
        "optimizer.maximize(n_iter=10)\n",
        "print('Optimal XGBoost hyperparameters per BayesianOptimization: ', optimizer.max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |   gamma   | learni... | max_depth | n_esti... |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9051  \u001b[0m | \u001b[0m 1.305   \u001b[0m | \u001b[0m 0.7821  \u001b[0m | \u001b[0m 5.507   \u001b[0m | \u001b[0m 73.73   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9069  \u001b[0m | \u001b[95m 4.912   \u001b[0m | \u001b[95m 0.5431  \u001b[0m | \u001b[95m 6.009   \u001b[0m | \u001b[95m 11.84   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9069  \u001b[0m | \u001b[95m 2.074   \u001b[0m | \u001b[95m 0.5049  \u001b[0m | \u001b[95m 7.434   \u001b[0m | \u001b[95m 81.36   \u001b[0m |\n",
            "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.9109  \u001b[0m | \u001b[95m 2.524   \u001b[0m | \u001b[95m 0.07528 \u001b[0m | \u001b[95m 4.305   \u001b[0m | \u001b[95m 91.41   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9086  \u001b[0m | \u001b[0m 1.854   \u001b[0m | \u001b[0m 0.4576  \u001b[0m | \u001b[0m 9.45    \u001b[0m | \u001b[0m 7.365   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 1.77    \u001b[0m | \u001b[0m 0.3848  \u001b[0m | \u001b[0m 7.482   \u001b[0m | \u001b[0m 68.23   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9104  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.4264  \u001b[0m | \u001b[0m 9.542   \u001b[0m | \u001b[0m 92.48   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8964  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 8.243   \u001b[0m | \u001b[0m 90.27   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9011  \u001b[0m | \u001b[0m 4.557   \u001b[0m | \u001b[0m 0.9928  \u001b[0m | \u001b[0m 3.356   \u001b[0m | \u001b[0m 19.56   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 2.191   \u001b[0m | \u001b[0m 0.3757  \u001b[0m | \u001b[0m 3.399   \u001b[0m | \u001b[0m 33.46   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 3.081   \u001b[0m | \u001b[0m 0.5498  \u001b[0m | \u001b[0m 6.272   \u001b[0m | \u001b[0m 13.52   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9063  \u001b[0m | \u001b[0m 2.299   \u001b[0m | \u001b[0m 0.3153  \u001b[0m | \u001b[0m 3.71    \u001b[0m | \u001b[0m 90.47   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.904   \u001b[0m | \u001b[0m 2.212   \u001b[0m | \u001b[0m 0.4955  \u001b[0m | \u001b[0m 3.796   \u001b[0m | \u001b[0m 91.73   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9063  \u001b[0m | \u001b[0m 2.34    \u001b[0m | \u001b[0m 0.7546  \u001b[0m | \u001b[0m 8.277   \u001b[0m | \u001b[0m 60.08   \u001b[0m |\n",
            "=========================================================================\n",
            "Optimal XGBoost hyperparameters per BayesianOptimization:  {'target': 0.9109481998779577, 'params': {'gamma': 2.5237645325941536, 'learning_rate': 0.07527698343684605, 'max_depth': 4.305164794463948, 'n_estimators': 91.4113851333633}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0-W-_xbN1Ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb728c7c-4f11-4749-eeb4-cddf60029d71"
      },
      "source": [
        "# XGBoost\n",
        "# https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py\n",
        "# https://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
        "# https://github.com/isakbosman/CS271P/blob/952919dab5f2fef80a38a4c8a614da7f5e63be5f/nbs/CS271P_Lab_2_XGBoost_Heart_Disease.ipynb\n",
        "\n",
        "#XGBoost Model w/ tweaked Hyperparameters\n",
        "\n",
        "# Hyperparameters calculated with BayesianOptimization\n",
        "xg_class = xgb.XGBClassifier(max_depth=int(optimizer.max['params']['max_depth']), \n",
        "                             learning_rate=optimizer.max['params']['learning_rate'],\n",
        "                             n_estimators = int(optimizer.max['params']['n_estimators']),\n",
        "                             gamma=optimizer.max['params']['gamma'], seed=7)\n",
        "\n",
        "xg_class.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_val, y_val)], early_stopping_rounds=4)\n",
        "\n",
        "preds = xg_class.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "# Baseline w/ Cross Validation\n",
        "xg_classcv = xgb.XGBClassifier(seed=7)\n",
        "xgcv = cross_val_score(xg_classcv, x, y, cv = 5)\n",
        "print(\"Accuracy: %0.2f%% (+/- %0.2f%%)\" % (xgcv.mean() * 100.0, xgcv.std() * 2))\n",
        "\n",
        "# K-Fold Cross Validation Approach \n",
        "cv = KFold(n_splits = 5, random_state = 7, shuffle = True)\n",
        "accuracy = cross_val_score(xg_classcv, x, y, scoring = 'accuracy', cv = cv, n_jobs = -1)\n",
        "print('Accuracy: %.3f%%  (+/- %.3f%%)' % (np.mean(accuracy) * 100.0, np.std(accuracy) ))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.073341\tvalidation_1-error:0.089431\n",
            "Multiple eval metrics have been passed: 'validation_1-error' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-error hasn't improved in 4 rounds.\n",
            "[1]\tvalidation_0-error:0.06752\tvalidation_1-error:0.093496\n",
            "[2]\tvalidation_0-error:0.06752\tvalidation_1-error:0.105691\n",
            "[3]\tvalidation_0-error:0.068102\tvalidation_1-error:0.101626\n",
            "[4]\tvalidation_0-error:0.066938\tvalidation_1-error:0.089431\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-error:0.073341\tvalidation_1-error:0.089431\n",
            "\n",
            "Accuracy: 90.43%\n",
            "Accuracy: 90.63% (+/- 0.07%)\n",
            "Accuracy: 91.405%  (+/- 0.008%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL1zNXEiPvnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae9d296-5532-43c6-9c8c-02b9777f87ad"
      },
      "source": [
        "#Leave-One-Out-Cross-Validation -- Source: https://machinelearningmastery.com/loocv-for-evaluating-machine-learning-algorithms/\n",
        "loocv = sk.model_selection.LeaveOneOut()\n",
        "\n",
        "accuracy = cross_val_score(xg_class, x, y, scoring='accuracy', cv=loocv, n_jobs=-1)\n",
        "print('Accuracy: %.3f%%  (+/- %.3f%%)' % (np.mean(accuracy) * 100.0, np.std(accuracy) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.527%  (+/- 0.278%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVF0rNE-Peu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fac98c6-2dc1-4ebf-c0e0-6ece0d7fe589"
      },
      "source": [
        "## Baseline w/ PCA Data\n",
        "\n",
        "xg_class_B = xgb.XGBClassifier(seed=7)\n",
        "xg_class_B.fit(B_train, B_y_train, eval_set=[(B_train, B_y_train), (B_val, B_y_val)], early_stopping_rounds=4)\n",
        "\n",
        "preds_B = xg_class_B.predict(B_test)\n",
        "\n",
        "accuracy_B = accuracy_score(B_y_test, preds_B)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_B * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-error:0.09837\tvalidation_1-error:0.130081\n",
            "Multiple eval metrics have been passed: 'validation_1-error' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-error hasn't improved in 4 rounds.\n",
            "[1]\tvalidation_0-error:0.090803\tvalidation_1-error:0.121951\n",
            "[2]\tvalidation_0-error:0.089057\tvalidation_1-error:0.121951\n",
            "[3]\tvalidation_0-error:0.086729\tvalidation_1-error:0.134146\n",
            "[4]\tvalidation_0-error:0.086147\tvalidation_1-error:0.138211\n",
            "[5]\tvalidation_0-error:0.087893\tvalidation_1-error:0.138211\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-error:0.090803\tvalidation_1-error:0.121951\n",
            "\n",
            "Accuracy: 89.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxF-VLZs2Anf",
        "outputId": "8cb2639d-e5dc-4432-80e2-7dd77c3b7178"
      },
      "source": [
        "# XGBoost Model Evaluation\n",
        "#Confusion Matrix for PCA\n",
        "#cm = skm.confusion_matrix(B_y_test, preds_B)\n",
        "#print('Confusion Matrix:', cm)\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = skm.confusion_matrix(y_test, preds)\n",
        "print('Confusion Matrix:', cm)\n",
        "\n",
        "# Senstivity\n",
        "# TP/(TP + FN)\n",
        "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Sensitivity: ', sensitivity )\n",
        "\n",
        "# Specificity\n",
        "# TN/(TN + FP)\n",
        "specificity = cm[0,0]/(cm[0,0] + cm[0,1])\n",
        "print('Specificity: ', specificity)\n",
        "\n",
        "# Precision\n",
        "# TP/(TP + FP)\n",
        "precision = cm[1,1]/(cm[1,1] + cm[0,1])\n",
        "print('Precision: ', precision)\n",
        "\n",
        "# Recall\n",
        "# TP/(TP + FN)\n",
        "recall = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Recall: ', recall)\n",
        "\n",
        "# F1 Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[376  20]\n",
            " [ 27  68]]\n",
            "Sensitivity:  0.7157894736842105\n",
            "Specificity:  0.9494949494949495\n",
            "Precision:  0.7727272727272727\n",
            "Recall:  0.7157894736842105\n",
            "F1 Score:  0.7431693989071039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C70-T4lT9AUb"
      },
      "source": [
        "**Confusion Matrix:  XGBoost with Tuned HyperParameters**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Sensitivity:  0.7157894736842105\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Specificity:  0.9494949494949495\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Precision:  0.7727272727272727\n",
        "\n",
        "---\n",
        "\n",
        "Recall:  0.7157894736842105\n",
        "\n",
        "---\n",
        "\n",
        "F1 Score: 0.7431693989071039\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZAbwzdWDGN5"
      },
      "source": [
        "**PCA CM Data for XGBOOST**\n",
        "\n",
        "Confusion Matrix: [[371  10]\n",
        " [ 35  75]]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sensitivity:  0.6818181818181818\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Specificity:  0.973753280839895\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Precision:  0.8823529411764706\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall:  0.6818181818181818\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "F1 Score:  0.7692307692307693"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpmSfz2y9L9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf898a3a-c374-4c5d-98b2-9ebc1d3564cc"
      },
      "source": [
        "# Support Vector Machine\n",
        "svm = SVC(random_state=7) \n",
        "cv = cross_val_score(svm, x, y, cv = 5)\n",
        "print(cv)\n",
        "print(\"Accuracy: %0.2f%% (+/- %0.2f%%)\" % (cv.mean() * 100.0, cv.std() * 2))\n",
        "\n",
        "svm.fit(x_train, y_train)\n",
        "preds = svm.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92668024 0.89613035 0.86558045 0.85743381 0.90020367]\n",
            "Accuracy: 88.92% (+/- 0.05%)\n",
            "Accuracy: 90.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz8tBfIBQljp"
      },
      "source": [
        "\n",
        "*   Baseline Model Accuracy (w/ Cross Validation): 90.22% +/- 0.07%\n",
        "*   Baseline: 91.65\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0IysdRbQKn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05471b0-411d-4dbb-a119-94b948d19e4a"
      },
      "source": [
        "# PCA svm\n",
        "svm_B = SVC(random_state=7)\n",
        "cv = cross_val_score(svm_B, B, y, cv=5)\n",
        "print(cv)\n",
        "print(\"Accuracy: %0.2f%% (+/- %0.2f%%)\" % (cv.mean() * 100.0, cv.std() * 2))\n",
        "\n",
        "svm_B.fit(B_train, B_y_train)\n",
        "preds_B = svm_B.predict(B_test)\n",
        "accuracy_B = accuracy_score(B_y_test, preds_B)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_B * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.93482688 0.93482688 0.84725051 0.86150713 0.88594705]\n",
            "Accuracy: 89.29% (+/- 0.07%)\n",
            "Accuracy: 90.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ftfnT3ml6S2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79842948-8dfa-46b7-f297-5663af272912"
      },
      "source": [
        "#Parameter Tuning for Support Vector Machine\n",
        "\n",
        "kernel = ['polynomial','linear','sigmoid']\n",
        "C = [100, 50, 10, 5, 1, 0.1]\n",
        "gamma = ['scale']\n",
        "param_grid = dict(C=C, gamma = gamma, kernel = kernel)\n",
        "grid_search = GridSearchCV(svm, param_grid = param_grid, n_jobs = -1, error_score = 0)\n",
        "grid_search.fit(x_train,y_train)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_estimator_)\n",
        "\n",
        "grid_pred = grid_search.predict(x_test)           \n",
        "accuracy_grid = accuracy_score(y_test, grid_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_grid * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "SVC(C=100, kernel='linear', random_state=7)\n",
            "Accuracy: 91.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDeS7nrbLlO-",
        "outputId": "6f078196-59cd-46fe-a64e-3e0486acba7f"
      },
      "source": [
        "#Parameter Tuning for Support Vector Machine PCA\n",
        "\n",
        "\n",
        "grid_search_B = GridSearchCV(svm_B, param_grid = param_grid, n_jobs = -1, error_score = 0 )\n",
        "grid_search_B.fit(B_train,B_y_train)\n",
        "\n",
        "print(grid_search_B.best_params_)\n",
        "print(grid_search_B.best_estimator_)\n",
        "\n",
        "grid_pred_B = grid_search_B.predict(B_test)           \n",
        "accuracy_grid_B = accuracy_score(B_y_test, grid_pred_B)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy_grid_B * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "SVC(C=0.1, kernel='linear', random_state=7)\n",
            "Accuracy: 91.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFTnLzIw5USf"
      },
      "source": [
        "LINEAR KERNEL GIVES 92.26% on this seed?\n",
        "RBF KERNEL Accuracy: 90.63%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qZZGLj4sQ3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c4829a-029d-4e2d-90bc-b50e70f3f34e"
      },
      "source": [
        "# Support Vector Machine Model Evaluation\n",
        "# Confusion Matrix\n",
        "\n",
        "#cm = skm.confusion_matrix(y_test, grid_pred)\n",
        "#print('Confusion Matrix:', cm)\n",
        "\n",
        "#Confusion Matrix for PCA B Data\n",
        "#cm = skm.confusion_matrix(B_y_test, preds_B)\n",
        "#print('Confusion Matrix:', cm)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = skm.confusion_matrix(y_test, preds)\n",
        "print('Confusion Matrix:', cm)\n",
        "\n",
        "# Senstivity\n",
        "# TP/(TP + FN)\n",
        "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Sensitivity: ', sensitivity )\n",
        "\n",
        "# Specificity\n",
        "# TN/(TN + FP)\n",
        "specificity = cm[0,0]/(cm[0,0] + cm[0,1])\n",
        "print('Specificity: ', specificity)\n",
        "\n",
        "# Precision\n",
        "# TP/(TP + FP)\n",
        "precision = cm[1,1]/(cm[1,1] + cm[0,1])\n",
        "print('Precision: ', precision)\n",
        "\n",
        "# Recall\n",
        "# TP/(TP + FN)\n",
        "recall = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Recall: ', recall)\n",
        "\n",
        "# F1 Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[390   6]\n",
            " [ 39  56]]\n",
            "Sensitivity:  0.5894736842105263\n",
            "Specificity:  0.9848484848484849\n",
            "Precision:  0.9032258064516129\n",
            "Recall:  0.5894736842105263\n",
            "F1 Score:  0.7133757961783439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbBSc8Lbe0io"
      },
      "source": [
        "**Confusion Matrix for Tuned HyperParameters**\n",
        "\n",
        "Confusion Matrix: [[379  17]\n",
        " [ 25  70]]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sensitivity:  0.7368421052631579\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Specificity:  0.9570707070707071\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Precision:  0.8045977011494253\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall:  0.7368421052631579\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "F1 Score:  0.7692307692307692"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMnVjwpfFope"
      },
      "source": [
        "**PCA Confusion Matrix for SVM** \n",
        "\n",
        "Confusion Matrix: [[371  10]\n",
        " [ 35  75]]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sensitivity:  0.6818181818181818\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Specificity:  0.973753280839895\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Precision:  0.8823529411764706\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall:  0.6818181818181818\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "F1 Score:  0.7692307692307693"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZJDwD6lpP2y"
      },
      "source": [
        "# Set LeakyReLU \n",
        "LeakyReLU = LeakyReLU(alpha=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcq7Y8tit6GO"
      },
      "source": [
        "# Make scorer accuracy\n",
        "score_acc = make_scorer(accuracy_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYf9YUyiX0-n"
      },
      "source": [
        "# Convert to int\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "y_test = LabelEncoder().fit_transform(y_test)\n",
        "y_train = LabelEncoder().fit_transform(y_train)\n",
        "y_val = LabelEncoder().fit_transform(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjXQrpUet7Sb"
      },
      "source": [
        "# Hyperparameter Tuning w/ BaysianOptimization for Deep Learning\n",
        "# https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/\n",
        "# Create function\n",
        "def nn_cl_bo(neurons, activation, optimizer, learning_rate,  batch_size, epochs, layers1, layers2,\n",
        "             normalization, dropout, dropout_rate):\n",
        "    #layeropt = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Ftrl']    # https://keras.io/api/optimizers/\n",
        "    #denseopt = {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
        "    #             'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
        "    #            'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
        "    layeropt = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
        "    denseopt= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
        "                 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
        "                 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
        "                 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
        "    actfx = ['relu', LeakyReLU, 'sigmoid', 'tanh', 'selu', 'elu']   # https://keras.io/api/layers/activations/\n",
        "    #actfx = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU]\n",
        "    neurons = round(neurons)\n",
        "    activation = actfx[round(activation)]\n",
        "    optimizer = denseopt[layeropt[round(optimizer)]]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    layers1 = round(layers1)\n",
        "    layers2 = round(layers2)\n",
        "    def nn_cl_fun():\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=17, activation=activation))   # Input Layer\n",
        "        if normalization > 0.5:\n",
        "          nn.add(BatchNormalization())\n",
        "        for i in range(layers1):\n",
        "          nn.add(Dense(neurons, activation=activation))     # Hidden layer(s)\n",
        "        if dropout > 0.5:\n",
        "          nn.add(Dropout(dropout_rate, seed = 7))     # Dropout Layer\n",
        "        for i in range(layers2):\n",
        "            nn.add(Dense(neurons, activation = activation))   # Hidden layer(s)\n",
        "        nn.add(Dense(1, activation='sigmoid'))    # Output Layer\n",
        "        nn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    pprint(vars(nn))\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
        "    accuracy = cross_val_score(nn, x_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDpqbn1euxaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f74520b-7856-4252-a188-f01c2e1dde71"
      },
      "source": [
        "# Set paramaters\n",
        "params_nn ={\n",
        "    'neurons': (2, 50), \n",
        "    'activation':(0, 5),\n",
        "    'optimizer':(0,8),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'batch_size':(20, 200), \n",
        "    'epochs':(20, 100),\n",
        "    'layers1':(1,3), # Hidden layer\n",
        "    'layers2':(1,3), # Hidden layer\n",
        "    'normalization':(0,1),\n",
        "    'dropout':(0,1),\n",
        "    'dropout_rate':(0,0.3)\n",
        "}\n",
        "\n",
        "# Run Bayesian Optimization\n",
        "mlp_optimizer = BayesianOptimization(nn_cl_bo, params_nn, random_state = 7)\n",
        "mlp_optimizer.maximize(init_points=25, n_iter=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8eacd5320>,\n",
            " 'sk_params': {'batch_size': 160, 'epochs': 98, 'verbose': 0}}\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9063  \u001b[0m | \u001b[0m 0.3815  \u001b[0m | \u001b[0m 160.4   \u001b[0m | \u001b[0m 0.4384  \u001b[0m | \u001b[0m 0.217   \u001b[0m | \u001b[0m 98.24   \u001b[0m | \u001b[0m 2.077   \u001b[0m | \u001b[0m 2.002   \u001b[0m | \u001b[0m 0.08133 \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 0.4999  \u001b[0m | \u001b[0m 5.434   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e65060e0>,\n",
            " 'sk_params': {'batch_size': 89, 'epochs': 93, 'verbose': 0}}\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8376  \u001b[0m | \u001b[0m 4.019   \u001b[0m | \u001b[0m 88.57   \u001b[0m | \u001b[0m 0.06594 \u001b[0m | \u001b[0m 0.08644 \u001b[0m | \u001b[0m 92.77   \u001b[0m | \u001b[0m 1.427   \u001b[0m | \u001b[0m 1.904   \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 3.195   \u001b[0m | \u001b[0m 0.6005  \u001b[0m | \u001b[0m 7.601   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8eafd1830>,\n",
            " 'sk_params': {'batch_size': 119, 'epochs': 62, 'verbose': 0}}\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.89    \u001b[0m | \u001b[0m 1.152   \u001b[0m | \u001b[0m 118.7   \u001b[0m | \u001b[0m 0.9091  \u001b[0m | \u001b[0m 0.03995 \u001b[0m | \u001b[0m 61.87   \u001b[0m | \u001b[0m 2.501   \u001b[0m | \u001b[0m 2.338   \u001b[0m | \u001b[0m 0.4731  \u001b[0m | \u001b[0m 11.83   \u001b[0m | \u001b[0m 0.4908  \u001b[0m | \u001b[0m 2.979   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8eadd73b0>,\n",
            " 'sk_params': {'batch_size': 86, 'epochs': 45, 'verbose': 0}}\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 2.387   \u001b[0m | \u001b[0m 85.86   \u001b[0m | \u001b[0m 0.8379  \u001b[0m | \u001b[0m 0.2306  \u001b[0m | \u001b[0m 45.12   \u001b[0m | \u001b[0m 2.145   \u001b[0m | \u001b[0m 1.552   \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 18.94   \u001b[0m | \u001b[0m 0.6574  \u001b[0m | \u001b[0m 2.963   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e670b200>,\n",
            " 'sk_params': {'batch_size': 149, 'epochs': 34, 'verbose': 0}}\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 2.295   \u001b[0m | \u001b[0m 149.5   \u001b[0m | \u001b[0m 0.413   \u001b[0m | \u001b[0m 0.2719  \u001b[0m | \u001b[0m 34.44   \u001b[0m | \u001b[0m 2.482   \u001b[0m | \u001b[0m 1.845   \u001b[0m | \u001b[0m 0.4322  \u001b[0m | \u001b[0m 32.45   \u001b[0m | \u001b[0m 0.5229  \u001b[0m | \u001b[0m 3.319   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8dac04cb0>,\n",
            " 'sk_params': {'batch_size': 37, 'epochs': 76, 'verbose': 0}}\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7863  \u001b[0m | \u001b[0m 0.007134\u001b[0m | \u001b[0m 36.61   \u001b[0m | \u001b[0m 0.7094  \u001b[0m | \u001b[0m 0.1573  \u001b[0m | \u001b[0m 75.69   \u001b[0m | \u001b[0m 2.911   \u001b[0m | \u001b[0m 2.366   \u001b[0m | \u001b[0m 0.0626  \u001b[0m | \u001b[0m 16.82   \u001b[0m | \u001b[0m 0.5926  \u001b[0m | \u001b[0m 1.881   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e68903b0>,\n",
            " 'sk_params': {'batch_size': 190, 'epochs': 87, 'verbose': 0}}\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 4.825   \u001b[0m | \u001b[0m 190.1   \u001b[0m | \u001b[0m 0.8484  \u001b[0m | \u001b[0m 0.1417  \u001b[0m | \u001b[0m 87.32   \u001b[0m | \u001b[0m 1.262   \u001b[0m | \u001b[0m 1.617   \u001b[0m | \u001b[0m 0.4684  \u001b[0m | \u001b[0m 37.61   \u001b[0m | \u001b[0m 0.4858  \u001b[0m | \u001b[0m 1.095   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8deac4dd0>,\n",
            " 'sk_params': {'batch_size': 78, 'epochs': 53, 'verbose': 0}}\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6841  \u001b[0m | \u001b[0m 1.718   \u001b[0m | \u001b[0m 78.4    \u001b[0m | \u001b[0m 0.3004  \u001b[0m | \u001b[0m 0.04965 \u001b[0m | \u001b[0m 53.19   \u001b[0m | \u001b[0m 1.896   \u001b[0m | \u001b[0m 2.55    \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 27.07   \u001b[0m | \u001b[0m 0.4606  \u001b[0m | \u001b[0m 6.226   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8f8b9a3b0>,\n",
            " 'sk_params': {'batch_size': 141, 'epochs': 23, 'verbose': 0}}\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6831  \u001b[0m | \u001b[0m 4.436   \u001b[0m | \u001b[0m 141.5   \u001b[0m | \u001b[0m 0.8005  \u001b[0m | \u001b[0m 0.2817  \u001b[0m | \u001b[0m 23.25   \u001b[0m | \u001b[0m 2.751   \u001b[0m | \u001b[0m 1.553   \u001b[0m | \u001b[0m 0.481   \u001b[0m | \u001b[0m 40.24   \u001b[0m | \u001b[0m 0.7172  \u001b[0m | \u001b[0m 1.177   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8deb04ef0>,\n",
            " 'sk_params': {'batch_size': 32, 'epochs': 54, 'verbose': 0}}\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8987  \u001b[0m | \u001b[0m 3.294   \u001b[0m | \u001b[0m 32.47   \u001b[0m | \u001b[0m 0.3571  \u001b[0m | \u001b[0m 0.2438  \u001b[0m | \u001b[0m 54.22   \u001b[0m | \u001b[0m 2.2     \u001b[0m | \u001b[0m 2.456   \u001b[0m | \u001b[0m 0.823   \u001b[0m | \u001b[0m 38.5    \u001b[0m | \u001b[0m 0.007143\u001b[0m | \u001b[0m 3.362   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8df3e4560>,\n",
            " 'sk_params': {'batch_size': 30, 'epochs': 86, 'verbose': 0}}\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 2.316   \u001b[0m | \u001b[0m 29.99   \u001b[0m | \u001b[0m 0.5414  \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 86.28   \u001b[0m | \u001b[0m 2.884   \u001b[0m | \u001b[0m 1.256   \u001b[0m | \u001b[0m 0.2381  \u001b[0m | \u001b[0m 33.64   \u001b[0m | \u001b[0m 0.1325  \u001b[0m | \u001b[0m 1.793   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e6b7d320>,\n",
            " 'sk_params': {'batch_size': 51, 'epochs': 23, 'verbose': 0}}\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 2.874   \u001b[0m | \u001b[0m 50.51   \u001b[0m | \u001b[0m 0.7822  \u001b[0m | \u001b[0m 0.2571  \u001b[0m | \u001b[0m 22.69   \u001b[0m | \u001b[0m 2.065   \u001b[0m | \u001b[0m 2.594   \u001b[0m | \u001b[0m 0.9754  \u001b[0m | \u001b[0m 15.16   \u001b[0m | \u001b[0m 0.1691  \u001b[0m | \u001b[0m 7.014   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e6a620e0>,\n",
            " 'sk_params': {'batch_size': 56, 'epochs': 88, 'verbose': 0}}\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6841  \u001b[0m | \u001b[0m 4.546   \u001b[0m | \u001b[0m 55.56   \u001b[0m | \u001b[0m 0.4415  \u001b[0m | \u001b[0m 0.2158  \u001b[0m | \u001b[0m 87.63   \u001b[0m | \u001b[0m 1.337   \u001b[0m | \u001b[0m 2.33    \u001b[0m | \u001b[0m 0.8098  \u001b[0m | \u001b[0m 28.39   \u001b[0m | \u001b[0m 0.1647  \u001b[0m | \u001b[0m 0.2842  \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e5475830>,\n",
            " 'sk_params': {'batch_size': 165, 'epochs': 49, 'verbose': 0}}\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8224  \u001b[0m | \u001b[0m 1.408   \u001b[0m | \u001b[0m 165.4   \u001b[0m | \u001b[0m 0.04477 \u001b[0m | \u001b[0m 0.002465\u001b[0m | \u001b[0m 48.93   \u001b[0m | \u001b[0m 1.127   \u001b[0m | \u001b[0m 1.299   \u001b[0m | \u001b[0m 0.03296 \u001b[0m | \u001b[0m 27.19   \u001b[0m | \u001b[0m 0.6967  \u001b[0m | \u001b[0m 3.416   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e6506b90>,\n",
            " 'sk_params': {'batch_size': 80, 'epochs': 99, 'verbose': 0}}\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8376  \u001b[0m | \u001b[0m 0.6729  \u001b[0m | \u001b[0m 79.64   \u001b[0m | \u001b[0m 0.5903  \u001b[0m | \u001b[0m 0.2822  \u001b[0m | \u001b[0m 99.4    \u001b[0m | \u001b[0m 1.483   \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m 0.8323  \u001b[0m | \u001b[0m 46.48   \u001b[0m | \u001b[0m 0.4586  \u001b[0m | \u001b[0m 6.172   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8eafd1560>,\n",
            " 'sk_params': {'batch_size': 130, 'epochs': 42, 'verbose': 0}}\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 4.331   \u001b[0m | \u001b[0m 129.7   \u001b[0m | \u001b[0m 0.8726  \u001b[0m | \u001b[0m 0.007171\u001b[0m | \u001b[0m 41.73   \u001b[0m | \u001b[0m 1.554   \u001b[0m | \u001b[0m 1.241   \u001b[0m | \u001b[0m 0.9116  \u001b[0m | \u001b[0m 3.461   \u001b[0m | \u001b[0m 0.6726  \u001b[0m | \u001b[0m 0.5707  \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8eb001680>,\n",
            " 'sk_params': {'batch_size': 95, 'epochs': 63, 'verbose': 0}}\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 1.804   \u001b[0m | \u001b[0m 95.26   \u001b[0m | \u001b[0m 0.1814  \u001b[0m | \u001b[0m 0.1563  \u001b[0m | \u001b[0m 62.8    \u001b[0m | \u001b[0m 1.634   \u001b[0m | \u001b[0m 2.474   \u001b[0m | \u001b[0m 0.1686  \u001b[0m | \u001b[0m 11.24   \u001b[0m | \u001b[0m 0.3545  \u001b[0m | \u001b[0m 3.027   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e6a6cf80>,\n",
            " 'sk_params': {'batch_size': 185, 'epochs': 50, 'verbose': 0}}\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8836  \u001b[0m | \u001b[0m 1.031   \u001b[0m | \u001b[0m 185.4   \u001b[0m | \u001b[0m 0.8281  \u001b[0m | \u001b[0m 0.03206 \u001b[0m | \u001b[0m 49.56   \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 1.902   \u001b[0m | \u001b[0m 0.2836  \u001b[0m | \u001b[0m 26.09   \u001b[0m | \u001b[0m 0.9226  \u001b[0m | \u001b[0m 3.06    \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8deac43b0>,\n",
            " 'sk_params': {'batch_size': 127, 'epochs': 80, 'verbose': 0}}\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 3.251   \u001b[0m | \u001b[0m 127.2   \u001b[0m | \u001b[0m 0.752   \u001b[0m | \u001b[0m 0.0185  \u001b[0m | \u001b[0m 79.59   \u001b[0m | \u001b[0m 2.893   \u001b[0m | \u001b[0m 2.207   \u001b[0m | \u001b[0m 0.2947  \u001b[0m | \u001b[0m 34.27   \u001b[0m | \u001b[0m 0.712   \u001b[0m | \u001b[0m 5.252   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8deb04dd0>,\n",
            " 'sk_params': {'batch_size': 195, 'epochs': 67, 'verbose': 0}}\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8073  \u001b[0m | \u001b[0m 0.7347  \u001b[0m | \u001b[0m 195.2   \u001b[0m | \u001b[0m 0.9554  \u001b[0m | \u001b[0m 0.1274  \u001b[0m | \u001b[0m 67.49   \u001b[0m | \u001b[0m 1.079   \u001b[0m | \u001b[0m 2.977   \u001b[0m | \u001b[0m 0.8206  \u001b[0m | \u001b[0m 32.55   \u001b[0m | \u001b[0m 0.7611  \u001b[0m | \u001b[0m 1.504   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8dac04320>,\n",
            " 'sk_params': {'batch_size': 64, 'epochs': 92, 'verbose': 0}}\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 1.538   \u001b[0m | \u001b[0m 64.35   \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 0.02757 \u001b[0m | \u001b[0m 91.65   \u001b[0m | \u001b[0m 1.925   \u001b[0m | \u001b[0m 1.89    \u001b[0m | \u001b[0m 0.1137  \u001b[0m | \u001b[0m 34.88   \u001b[0m | \u001b[0m 0.8169  \u001b[0m | \u001b[0m 5.036   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e6568950>,\n",
            " 'sk_params': {'batch_size': 161, 'epochs': 66, 'verbose': 0}}\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8911  \u001b[0m | \u001b[0m 1.21    \u001b[0m | \u001b[0m 161.4   \u001b[0m | \u001b[0m 0.1457  \u001b[0m | \u001b[0m 0.2482  \u001b[0m | \u001b[0m 66.46   \u001b[0m | \u001b[0m 1.579   \u001b[0m | \u001b[0m 2.026   \u001b[0m | \u001b[0m 0.6326  \u001b[0m | \u001b[0m 14.41   \u001b[0m | \u001b[0m 0.8469  \u001b[0m | \u001b[0m 3.37    \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e6a71440>,\n",
            " 'sk_params': {'batch_size': 170, 'epochs': 45, 'verbose': 0}}\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.721   \u001b[0m | \u001b[0m 4.462   \u001b[0m | \u001b[0m 170.4   \u001b[0m | \u001b[0m 0.09935 \u001b[0m | \u001b[0m 0.1939  \u001b[0m | \u001b[0m 44.84   \u001b[0m | \u001b[0m 2.508   \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 0.463   \u001b[0m | \u001b[0m 44.98   \u001b[0m | \u001b[0m 0.05725 \u001b[0m | \u001b[0m 4.459   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8dde6a3b0>,\n",
            " 'sk_params': {'batch_size': 26, 'epochs': 92, 'verbose': 0}}\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 1.64    \u001b[0m | \u001b[0m 26.35   \u001b[0m | \u001b[0m 0.7535  \u001b[0m | \u001b[0m 0.1685  \u001b[0m | \u001b[0m 91.53   \u001b[0m | \u001b[0m 2.197   \u001b[0m | \u001b[0m 1.674   \u001b[0m | \u001b[0m 0.9854  \u001b[0m | \u001b[0m 7.554   \u001b[0m | \u001b[0m 0.0526  \u001b[0m | \u001b[0m 5.861   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e5431830>,\n",
            " 'sk_params': {'batch_size': 85, 'epochs': 91, 'verbose': 0}}\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6841  \u001b[0m | \u001b[0m 1.854   \u001b[0m | \u001b[0m 85.06   \u001b[0m | \u001b[0m 0.8765  \u001b[0m | \u001b[0m 0.09819 \u001b[0m | \u001b[0m 91.12   \u001b[0m | \u001b[0m 2.288   \u001b[0m | \u001b[0m 1.658   \u001b[0m | \u001b[0m 0.06894 \u001b[0m | \u001b[0m 13.77   \u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 3.242   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8ec3cfb90>,\n",
            " 'sk_params': {'batch_size': 85, 'epochs': 85, 'verbose': 0}}\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 0.3632  \u001b[0m | \u001b[0m 84.96   \u001b[0m | \u001b[0m 0.09583 \u001b[0m | \u001b[0m 0.2137  \u001b[0m | \u001b[0m 84.78   \u001b[0m | \u001b[0m 1.091   \u001b[0m | \u001b[0m 2.022   \u001b[0m | \u001b[0m 0.1671  \u001b[0m | \u001b[0m 48.01   \u001b[0m | \u001b[0m 0.533   \u001b[0m | \u001b[0m 1.253   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8e6a6ca70>,\n",
            " 'sk_params': {'batch_size': 114, 'epochs': 94, 'verbose': 0}}\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8266  \u001b[0m | \u001b[0m 1.498   \u001b[0m | \u001b[0m 113.8   \u001b[0m | \u001b[0m 0.4451  \u001b[0m | \u001b[0m 0.1469  \u001b[0m | \u001b[0m 93.56   \u001b[0m | \u001b[0m 1.222   \u001b[0m | \u001b[0m 2.833   \u001b[0m | \u001b[0m 0.6422  \u001b[0m | \u001b[0m 3.224   \u001b[0m | \u001b[0m 0.6929  \u001b[0m | \u001b[0m 2.744   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8de8fe560>,\n",
            " 'sk_params': {'batch_size': 32, 'epochs': 58, 'verbose': 0}}\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8062  \u001b[0m | \u001b[0m 0.1739  \u001b[0m | \u001b[0m 32.43   \u001b[0m | \u001b[0m 0.2411  \u001b[0m | \u001b[0m 0.1555  \u001b[0m | \u001b[0m 58.18   \u001b[0m | \u001b[0m 2.702   \u001b[0m | \u001b[0m 1.092   \u001b[0m | \u001b[0m 0.9883  \u001b[0m | \u001b[0m 9.317   \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 4.365   \u001b[0m |\n",
            "{'build_fn': <function nn_cl_bo.<locals>.nn_cl_fun at 0x7fb8df3f8290>,\n",
            " 'sk_params': {'batch_size': 65, 'epochs': 58, 'verbose': 0}}\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8603  \u001b[0m | \u001b[0m 0.8552  \u001b[0m | \u001b[0m 64.73   \u001b[0m | \u001b[0m 0.1906  \u001b[0m | \u001b[0m 0.2836  \u001b[0m | \u001b[0m 58.03   \u001b[0m | \u001b[0m 1.114   \u001b[0m | \u001b[0m 2.759   \u001b[0m | \u001b[0m 0.3543  \u001b[0m | \u001b[0m 18.19   \u001b[0m | \u001b[0m 0.3376  \u001b[0m | \u001b[0m 3.481   \u001b[0m |\n",
            "=============================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTclXvAPrJ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612c8100-c124-4908-b585-46edad8935d8"
      },
      "source": [
        "# Hyperparameter Tuning w/ BaysianOptimization for Deep Learning\n",
        "params_nn_ = mlp_optimizer.max['params']\n",
        "learning_rate = params_nn_['learning_rate']\n",
        "actfx = ['relu', LeakyReLU, 'sigmoid', 'tanh', 'selu', 'elu'] \n",
        "params_nn_['activation'] = actfx[round(params_nn_['activation'])]\n",
        "params_nn_['batch_size'] = round(params_nn_['batch_size'])\n",
        "params_nn_['epochs'] = round(params_nn_['epochs'])\n",
        "params_nn_['layers1'] = round(params_nn_['layers1'])\n",
        "params_nn_['layers2'] = round(params_nn_['layers2'])\n",
        "params_nn_['neurons'] = round(params_nn_['neurons'])\n",
        "layeropt = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
        "denseopt= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
        "                 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
        "                 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
        "                 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}       \n",
        "params_nn_['optimizer'] = denseopt[layeropt[round(params_nn_['optimizer'])]]\n",
        "params_nn_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 160,\n",
              " 'dropout': 0.4384092314408935,\n",
              " 'dropout_rate': 0.21703955334928235,\n",
              " 'epochs': 98,\n",
              " 'layers1': 2,\n",
              " 'layers2': 2,\n",
              " 'learning_rate': 0.08133062202616392,\n",
              " 'neurons': 15,\n",
              " 'normalization': 0.49988250082555996,\n",
              " 'optimizer': <keras.optimizer_v2.adamax.Adamax at 0x7fb8ec405550>}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhhD8OROLFaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26097cb-d658-419d-f48b-52e135e50cec"
      },
      "source": [
        "# Fitting Neural Networks\n",
        "def nn_cl_fun():\n",
        "  nn = Sequential()\n",
        "  nn.add(Dense(params_nn_['neurons'], input_dim=17, activation=params_nn_['activation']))\n",
        "  if params_nn_['normalization'] > 0.5:\n",
        "    nn.add(BatchNormalization())\n",
        "  for i in range(params_nn_['layers1']):\n",
        "    nn.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\n",
        "  if params_nn_['dropout'] > 0.5:\n",
        "    nn.add(Dropout(params_nn_['dropout_rate'], seed=7))\n",
        "  for i in range(params_nn_['layers2']):\n",
        "    nn.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\n",
        "  nn.add(Dense(1, activation='sigmoid'))\n",
        "  nn.compile(loss='binary_crossentropy', optimizer=params_nn_['optimizer'], metrics=['accuracy'])\n",
        "  return nn\n",
        "es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
        "nn = KerasClassifier(build_fn=nn_cl_fun, epochs=params_nn_['epochs'], batch_size=params_nn_['batch_size'],\n",
        "                         verbose=0)\n",
        "nn.fit(x_train, y_train, validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/98\n",
            "11/11 [==============================] - 1s 25ms/step - loss: 1.5415 - accuracy: 0.7503 - val_loss: 0.5263 - val_accuracy: 0.8065\n",
            "Epoch 2/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5232 - accuracy: 0.8062 - val_loss: 0.5134 - val_accuracy: 0.8065\n",
            "Epoch 3/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.8062 - val_loss: 0.4733 - val_accuracy: 0.8065\n",
            "Epoch 4/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8062 - val_loss: 0.4039 - val_accuracy: 0.8065\n",
            "Epoch 5/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8062 - val_loss: 0.3860 - val_accuracy: 0.8065\n",
            "Epoch 6/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8062 - val_loss: 0.3411 - val_accuracy: 0.8065\n",
            "Epoch 7/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3348 - accuracy: 0.8126 - val_loss: 0.3444 - val_accuracy: 0.8411\n",
            "Epoch 8/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3723 - accuracy: 0.8213 - val_loss: 0.2974 - val_accuracy: 0.8941\n",
            "Epoch 9/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8749 - val_loss: 0.3094 - val_accuracy: 0.8697\n",
            "Epoch 10/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8580 - val_loss: 0.3717 - val_accuracy: 0.8554\n",
            "Epoch 11/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3531 - accuracy: 0.8492 - val_loss: 0.3160 - val_accuracy: 0.8534\n",
            "Epoch 12/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3058 - accuracy: 0.8795 - val_loss: 0.2878 - val_accuracy: 0.8961\n",
            "Epoch 13/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2913 - accuracy: 0.8865 - val_loss: 0.3460 - val_accuracy: 0.8432\n",
            "Epoch 14/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8766 - val_loss: 0.2863 - val_accuracy: 0.8941\n",
            "Epoch 15/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3063 - accuracy: 0.8795 - val_loss: 0.2643 - val_accuracy: 0.9002\n",
            "Epoch 16/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3388 - accuracy: 0.8586 - val_loss: 0.2862 - val_accuracy: 0.8941\n",
            "Epoch 17/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8620 - val_loss: 0.2932 - val_accuracy: 0.8839\n",
            "Epoch 18/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3063 - accuracy: 0.8783 - val_loss: 0.2626 - val_accuracy: 0.8961\n",
            "Epoch 19/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2802 - accuracy: 0.8900 - val_loss: 0.2566 - val_accuracy: 0.9022\n",
            "Epoch 20/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3064 - accuracy: 0.8795 - val_loss: 0.3809 - val_accuracy: 0.8330\n",
            "Epoch 21/98\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8783 - val_loss: 0.2526 - val_accuracy: 0.9022\n",
            "Epoch 22/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2743 - accuracy: 0.8906 - val_loss: 0.2470 - val_accuracy: 0.8982\n",
            "Epoch 23/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.8946 - val_loss: 0.2738 - val_accuracy: 0.8921\n",
            "Epoch 24/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.8946 - val_loss: 0.2487 - val_accuracy: 0.9002\n",
            "Epoch 25/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2882 - accuracy: 0.8830 - val_loss: 0.2610 - val_accuracy: 0.8839\n",
            "Epoch 26/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2762 - accuracy: 0.8882 - val_loss: 0.2458 - val_accuracy: 0.8961\n",
            "Epoch 27/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.8859 - val_loss: 0.2543 - val_accuracy: 0.8982\n",
            "Epoch 28/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2843 - accuracy: 0.8813 - val_loss: 0.2500 - val_accuracy: 0.8982\n",
            "Epoch 29/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.8783 - val_loss: 0.3443 - val_accuracy: 0.8473\n",
            "Epoch 30/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8533 - val_loss: 0.3642 - val_accuracy: 0.9022\n",
            "Epoch 31/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2994 - accuracy: 0.8906 - val_loss: 0.2517 - val_accuracy: 0.8961\n",
            "Epoch 32/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2687 - accuracy: 0.8923 - val_loss: 0.2717 - val_accuracy: 0.9022\n",
            "Epoch 33/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2670 - accuracy: 0.8877 - val_loss: 0.2733 - val_accuracy: 0.9022\n",
            "Epoch 34/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2738 - accuracy: 0.8894 - val_loss: 0.2959 - val_accuracy: 0.9002\n",
            "Epoch 35/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8894 - val_loss: 0.2566 - val_accuracy: 0.8900\n",
            "Epoch 36/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3195 - accuracy: 0.8626 - val_loss: 0.3717 - val_accuracy: 0.8961\n",
            "Epoch 37/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3319 - accuracy: 0.8644 - val_loss: 0.2596 - val_accuracy: 0.9002\n",
            "Epoch 38/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2885 - accuracy: 0.8795 - val_loss: 0.2423 - val_accuracy: 0.8961\n",
            "Epoch 39/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2901 - accuracy: 0.8853 - val_loss: 0.2785 - val_accuracy: 0.9002\n",
            "Epoch 40/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2631 - accuracy: 0.8964 - val_loss: 0.2350 - val_accuracy: 0.9002\n",
            "Epoch 41/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2824 - accuracy: 0.8882 - val_loss: 0.2680 - val_accuracy: 0.8982\n",
            "Epoch 42/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2639 - accuracy: 0.8929 - val_loss: 0.2328 - val_accuracy: 0.9022\n",
            "Epoch 43/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2813 - accuracy: 0.8900 - val_loss: 0.2448 - val_accuracy: 0.9022\n",
            "Epoch 44/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2731 - accuracy: 0.8853 - val_loss: 0.2853 - val_accuracy: 0.9022\n",
            "Epoch 45/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.8906 - val_loss: 0.2909 - val_accuracy: 0.8534\n",
            "Epoch 46/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3030 - accuracy: 0.8719 - val_loss: 0.3148 - val_accuracy: 0.8921\n",
            "Epoch 47/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2735 - accuracy: 0.8912 - val_loss: 0.2334 - val_accuracy: 0.8982\n",
            "Epoch 48/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.8888 - val_loss: 0.2661 - val_accuracy: 0.8839\n",
            "Epoch 49/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8766 - val_loss: 0.2769 - val_accuracy: 0.8982\n",
            "Epoch 50/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2680 - accuracy: 0.8958 - val_loss: 0.2746 - val_accuracy: 0.8961\n",
            "Epoch 51/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2622 - accuracy: 0.9028 - val_loss: 0.2328 - val_accuracy: 0.9063\n",
            "Epoch 52/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2657 - accuracy: 0.8929 - val_loss: 0.2574 - val_accuracy: 0.8982\n",
            "Epoch 53/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.8900 - val_loss: 0.2394 - val_accuracy: 0.9022\n",
            "Epoch 54/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8731 - val_loss: 0.2632 - val_accuracy: 0.9002\n",
            "Epoch 55/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2767 - accuracy: 0.8888 - val_loss: 0.2333 - val_accuracy: 0.9022\n",
            "Epoch 56/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2680 - accuracy: 0.9010 - val_loss: 0.2706 - val_accuracy: 0.8982\n",
            "Epoch 57/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2601 - accuracy: 0.8993 - val_loss: 0.2684 - val_accuracy: 0.8819\n",
            "Epoch 58/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.9010 - val_loss: 0.2337 - val_accuracy: 0.9002\n",
            "Epoch 59/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.8993 - val_loss: 0.2325 - val_accuracy: 0.8982\n",
            "Epoch 60/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2670 - accuracy: 0.8952 - val_loss: 0.2492 - val_accuracy: 0.8982\n",
            "Epoch 61/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2656 - accuracy: 0.8958 - val_loss: 0.2670 - val_accuracy: 0.8859\n",
            "Epoch 62/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.8894 - val_loss: 0.2795 - val_accuracy: 0.9002\n",
            "Epoch 63/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.9005 - val_loss: 0.2396 - val_accuracy: 0.9022\n",
            "Epoch 64/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2496 - accuracy: 0.9069 - val_loss: 0.2387 - val_accuracy: 0.9022\n",
            "Epoch 65/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2536 - accuracy: 0.8981 - val_loss: 0.2308 - val_accuracy: 0.9022\n",
            "Epoch 66/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2579 - accuracy: 0.8987 - val_loss: 0.2326 - val_accuracy: 0.8982\n",
            "Epoch 67/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2580 - accuracy: 0.8970 - val_loss: 0.2369 - val_accuracy: 0.9022\n",
            "Epoch 68/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.8912 - val_loss: 0.3949 - val_accuracy: 0.8432\n",
            "Epoch 69/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8731 - val_loss: 0.2564 - val_accuracy: 0.8982\n",
            "Epoch 70/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.8952 - val_loss: 0.2652 - val_accuracy: 0.9002\n",
            "Epoch 71/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2778 - accuracy: 0.8946 - val_loss: 0.2612 - val_accuracy: 0.8900\n",
            "Epoch 72/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.8935 - val_loss: 0.2320 - val_accuracy: 0.9063\n",
            "Epoch 73/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2835 - accuracy: 0.8929 - val_loss: 0.2423 - val_accuracy: 0.9043\n",
            "Epoch 74/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8783 - val_loss: 0.2568 - val_accuracy: 0.8900\n",
            "Epoch 75/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2737 - accuracy: 0.8923 - val_loss: 0.2324 - val_accuracy: 0.9063\n",
            "Epoch 76/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.8976 - val_loss: 0.2329 - val_accuracy: 0.8982\n",
            "Epoch 77/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9016 - val_loss: 0.2564 - val_accuracy: 0.9002\n",
            "Epoch 78/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2546 - accuracy: 0.9051 - val_loss: 0.2314 - val_accuracy: 0.9063\n",
            "Epoch 79/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2490 - accuracy: 0.9040 - val_loss: 0.2290 - val_accuracy: 0.9063\n",
            "Epoch 80/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.8946 - val_loss: 0.2370 - val_accuracy: 0.9022\n",
            "Epoch 81/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.8882 - val_loss: 0.2652 - val_accuracy: 0.9002\n",
            "Epoch 82/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2602 - accuracy: 0.8970 - val_loss: 0.2297 - val_accuracy: 0.9022\n",
            "Epoch 83/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2854 - accuracy: 0.8859 - val_loss: 0.2646 - val_accuracy: 0.8839\n",
            "Epoch 84/98\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2671 - accuracy: 0.8981 - val_loss: 0.2361 - val_accuracy: 0.8982\n",
            "Epoch 85/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2796 - accuracy: 0.8847 - val_loss: 0.2372 - val_accuracy: 0.8982\n",
            "Epoch 86/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8894 - val_loss: 0.2571 - val_accuracy: 0.8941\n",
            "Epoch 87/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2706 - accuracy: 0.8941 - val_loss: 0.2415 - val_accuracy: 0.9043\n",
            "Epoch 88/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2538 - accuracy: 0.9010 - val_loss: 0.2367 - val_accuracy: 0.8982\n",
            "Epoch 89/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2656 - accuracy: 0.8935 - val_loss: 0.2395 - val_accuracy: 0.8982\n",
            "Epoch 90/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2602 - accuracy: 0.8987 - val_loss: 0.2413 - val_accuracy: 0.9043\n",
            "Epoch 91/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2583 - accuracy: 0.8999 - val_loss: 0.2478 - val_accuracy: 0.9022\n",
            "Epoch 92/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2552 - accuracy: 0.9057 - val_loss: 0.2442 - val_accuracy: 0.9002\n",
            "Epoch 93/98\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2782 - accuracy: 0.8760 - val_loss: 0.2367 - val_accuracy: 0.9084\n",
            "Epoch 94/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2549 - accuracy: 0.9028 - val_loss: 0.2750 - val_accuracy: 0.8941\n",
            "Epoch 95/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.8912 - val_loss: 0.2599 - val_accuracy: 0.8859\n",
            "Epoch 96/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2597 - accuracy: 0.9028 - val_loss: 0.2331 - val_accuracy: 0.8961\n",
            "Epoch 97/98\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.9069 - val_loss: 0.2730 - val_accuracy: 0.8961\n",
            "Epoch 98/98\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2668 - accuracy: 0.8894 - val_loss: 0.2378 - val_accuracy: 0.9043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb8dddb0cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haLaPCvKrWaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2a309a-ad63-494d-b269-b6bf74029603"
      },
      "source": [
        "preds = nn.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test,preds)\n",
        "print('Accuracy: %.3f' % accuracy) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfcA94vkr_83"
      },
      "source": [
        "# Deep Learning\n",
        "# https://machinelearningmastery.com/neural-network-for-cancer-survival-dataset/\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "# https://stackoverflow.com/questions/68836551/keras-attributeerror-sequential-object-has-no-attribute-predict-classes\n",
        "# Source for drop in performance: https://www.quora.com/Why-is-xgboost-given-so-much-less-attention-than-deep-learning-despite-its-ubiquity-in-winning-Kaggle-solutions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH6L-YG1Rg8E",
        "outputId": "62497151-5cb9-4e56-9b36-b378fc5c1739"
      },
      "source": [
        "# MLP Model Evaluation\n",
        "\n",
        "# TP = cm[1,1]\n",
        "# TN = cm[0,0]\n",
        "# FP = cm[0,1]\n",
        "# FN = cm[1,0]\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = skm.confusion_matrix(y_test, preds)\n",
        "print('Confusion Matrix:', cm)\n",
        "\n",
        "# Senstivity\n",
        "# TP/(TP + FN)\n",
        "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Sensitivity: ', sensitivity )\n",
        "\n",
        "# Specificity\n",
        "# TN/(TN + FP)\n",
        "specificity = cm[0,0]/(cm[0,0] + cm[0,1])\n",
        "print('Specificity: ', specificity)\n",
        "\n",
        "# Precision\n",
        "# TP/(TP + FP)\n",
        "precision = cm[1,1]/(cm[1,1] + cm[0,1])\n",
        "print('Precision: ', precision)\n",
        "\n",
        "# Recall\n",
        "# TP/(TP + FN)\n",
        "recall = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "print('Recall: ', recall)\n",
        "\n",
        "# F1 Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: [[393   3]\n",
            " [ 44  51]]\n",
            "Sensitivity:  0.5368421052631579\n",
            "Specificity:  0.9924242424242424\n",
            "Precision:  0.9444444444444444\n",
            "Recall:  0.5368421052631579\n",
            "F1 Score:  0.6845637583892618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e81-eQAoRrbw"
      },
      "source": [
        "**Confusion Matrix for Tuned HyperParameters**\n",
        "\n",
        "Confusion Matrix: [[383  13]\n",
        " [ 37  58]]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Sensitivity:  0.6105263157894737\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Specificity:  0.9671717171717171\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Precision:  0.8169014084507042\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall:  0.6105263157894737\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "F1 Score:  0.6987951807228917"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R7bsJTp333n"
      },
      "source": [
        ":) done\n"
      ]
    }
  ]
}